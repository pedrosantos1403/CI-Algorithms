{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nomes: Pedro Santos e Vinícius Nascimento\n",
    "\n",
    "Tarefa: Comparar a atuação de uma random forest com a atuação de uma rede neural, ambas serão usadas para prever a diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminaries\n",
    "\n",
    "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set (Internet Access needed)\n",
    "\n",
    "##url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('pima-indians-diabetes.data', names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>10</td>\n",
       "      <td>111</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.141</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>13</td>\n",
       "      <td>106</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.2</td>\n",
       "      <td>0.251</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>13</td>\n",
       "      <td>106</td>\n",
       "      <td>72</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.178</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>10</td>\n",
       "      <td>68</td>\n",
       "      <td>106</td>\n",
       "      <td>23</td>\n",
       "      <td>49</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.285</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>68</td>\n",
       "      <td>32</td>\n",
       "      <td>210</td>\n",
       "      <td>39.9</td>\n",
       "      <td>0.381</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "667              10                     111              70              27   \n",
       "274              13                     106              70               0   \n",
       "86               13                     106              72              54   \n",
       "672              10                      68             106              23   \n",
       "452               0                      91              68              32   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "667        0  27.5              0.141   40             1  \n",
       "274        0  34.2              0.251   52             0  \n",
       "86         0  36.6              0.178   45             0  \n",
       "672       49  35.5              0.285   47             0  \n",
       "452      210  39.9              0.381   25             0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colocando os dados de todas as entradas em X e colocando os dados das saídas em Y\n",
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.781\n",
      "roc-auc is 0.828\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model\n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential([\n",
    "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_17 (Dense)            (None, 12)                108       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 1s 16ms/step - loss: 0.6758 - accuracy: 0.5972 - val_loss: 0.6990 - val_accuracy: 0.5677\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6604 - accuracy: 0.6059 - val_loss: 0.6833 - val_accuracy: 0.5938\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6462 - accuracy: 0.6250 - val_loss: 0.6693 - val_accuracy: 0.5990\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6335 - accuracy: 0.6389 - val_loss: 0.6568 - val_accuracy: 0.6250\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6219 - accuracy: 0.6615 - val_loss: 0.6454 - val_accuracy: 0.6302\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6113 - accuracy: 0.6719 - val_loss: 0.6350 - val_accuracy: 0.6302\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6016 - accuracy: 0.6858 - val_loss: 0.6255 - val_accuracy: 0.6354\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5925 - accuracy: 0.6944 - val_loss: 0.6168 - val_accuracy: 0.6458\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5841 - accuracy: 0.7066 - val_loss: 0.6088 - val_accuracy: 0.6562\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5764 - accuracy: 0.7205 - val_loss: 0.6015 - val_accuracy: 0.6719\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5693 - accuracy: 0.7240 - val_loss: 0.5947 - val_accuracy: 0.6823\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5626 - accuracy: 0.7292 - val_loss: 0.5884 - val_accuracy: 0.6823\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5565 - accuracy: 0.7396 - val_loss: 0.5826 - val_accuracy: 0.6823\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5507 - accuracy: 0.7396 - val_loss: 0.5774 - val_accuracy: 0.6771\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5455 - accuracy: 0.7431 - val_loss: 0.5726 - val_accuracy: 0.6823\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.7500 - val_loss: 0.5682 - val_accuracy: 0.6927\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7483 - val_loss: 0.5640 - val_accuracy: 0.6979\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7448 - val_loss: 0.5602 - val_accuracy: 0.6979\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5276 - accuracy: 0.7483 - val_loss: 0.5566 - val_accuracy: 0.6979\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7483 - val_loss: 0.5533 - val_accuracy: 0.6875\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5204 - accuracy: 0.7500 - val_loss: 0.5502 - val_accuracy: 0.6927\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5171 - accuracy: 0.7535 - val_loss: 0.5474 - val_accuracy: 0.7031\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5141 - accuracy: 0.7569 - val_loss: 0.5449 - val_accuracy: 0.7031\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7604 - val_loss: 0.5425 - val_accuracy: 0.7135\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7639 - val_loss: 0.5403 - val_accuracy: 0.7135\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7639 - val_loss: 0.5382 - val_accuracy: 0.7188\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7656 - val_loss: 0.5362 - val_accuracy: 0.7188\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7656 - val_loss: 0.5344 - val_accuracy: 0.7240\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.7639 - val_loss: 0.5327 - val_accuracy: 0.7240\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.7656 - val_loss: 0.5311 - val_accuracy: 0.7344\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4955 - accuracy: 0.7691 - val_loss: 0.5297 - val_accuracy: 0.7344\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.7708 - val_loss: 0.5283 - val_accuracy: 0.7344\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4920 - accuracy: 0.7691 - val_loss: 0.5270 - val_accuracy: 0.7344\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4904 - accuracy: 0.7639 - val_loss: 0.5259 - val_accuracy: 0.7344\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.7656 - val_loss: 0.5248 - val_accuracy: 0.7396\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7656 - val_loss: 0.5237 - val_accuracy: 0.7448\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7639 - val_loss: 0.5228 - val_accuracy: 0.7500\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7656 - val_loss: 0.5219 - val_accuracy: 0.7500\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.7708 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4823 - accuracy: 0.7674 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4812 - accuracy: 0.7726 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7726 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4790 - accuracy: 0.7726 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7726 - val_loss: 0.5176 - val_accuracy: 0.7552\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7743 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4761 - accuracy: 0.7743 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7778 - val_loss: 0.5161 - val_accuracy: 0.7500\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4744 - accuracy: 0.7778 - val_loss: 0.5157 - val_accuracy: 0.7500\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7795 - val_loss: 0.5153 - val_accuracy: 0.7500\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4729 - accuracy: 0.7760 - val_loss: 0.5149 - val_accuracy: 0.7500\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7760 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7795 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7795 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7795 - val_loss: 0.5137 - val_accuracy: 0.7500\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7812 - val_loss: 0.5134 - val_accuracy: 0.7500\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7778 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7795 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7795 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7795 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7812 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7795 - val_loss: 0.5122 - val_accuracy: 0.7448\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7812 - val_loss: 0.5121 - val_accuracy: 0.7448\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7812 - val_loss: 0.5119 - val_accuracy: 0.7448\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7795 - val_loss: 0.5118 - val_accuracy: 0.7500\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7830 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7830 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4624 - accuracy: 0.7847 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7847 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7882 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7882 - val_loss: 0.5111 - val_accuracy: 0.7396\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4603 - accuracy: 0.7882 - val_loss: 0.5110 - val_accuracy: 0.7396\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7865 - val_loss: 0.5109 - val_accuracy: 0.7396\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7882 - val_loss: 0.5108 - val_accuracy: 0.7396\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7847 - val_loss: 0.5107 - val_accuracy: 0.7396\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7882 - val_loss: 0.5106 - val_accuracy: 0.7396\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7899 - val_loss: 0.5106 - val_accuracy: 0.7396\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7917 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7882 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7882 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.7917 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7899 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7899 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.7899 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4555 - accuracy: 0.7899 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7882 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.7899 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4546 - accuracy: 0.7865 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4543 - accuracy: 0.7882 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4541 - accuracy: 0.7865 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7865 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4534 - accuracy: 0.7865 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4534 - accuracy: 0.7865 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.7882 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7865 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4526 - accuracy: 0.7899 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.7882 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4521 - accuracy: 0.7917 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4519 - accuracy: 0.7899 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.7917 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4515 - accuracy: 0.7917 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7917 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7917 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7917 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7917 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7934 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7969 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7934 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7934 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4485 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7951 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7951 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7951 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7951 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7969 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7969 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7951 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7951 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7934 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.7934 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7934 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4465 - accuracy: 0.7934 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7934 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7951 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.7951 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.7934 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7934 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7934 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4456 - accuracy: 0.7934 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4454 - accuracy: 0.7951 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4454 - accuracy: 0.7934 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4451 - accuracy: 0.7951 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4446 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4443 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7934 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7934 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7934 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7934 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7934 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7934 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7934 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7934 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4424 - accuracy: 0.7934 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7934 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7934 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7934 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7934 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7934 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7934 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7934 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7934 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7934 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7934 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7951 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7934 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.7951 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7951 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7951 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7969 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4401 - accuracy: 0.7969 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4400 - accuracy: 0.7969 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7969 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7969 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7969 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.7969 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7969 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7969 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7969 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7969 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7986 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7986 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7986 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7969 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7986 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7969 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7969 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7969 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7969 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7969 - val_loss: 0.5112 - val_accuracy: 0.7396\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4377 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7396\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7396\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "#y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "#y_pred_prob_nn_1 = model_1.predict(X_test_norm)\n",
    "\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)\n",
    "y_pred_class_nn_1 = (y_pred_prob_nn_1 > 0.5).astype(\"int32\")\n",
    "\n",
    "#O método \"predict_classes\" não funciona nas versões do Keras superior a 2.5 \n",
    "\n",
    "# A indicação da correção se encontra em https://keras.rstudio.com/reference/predict_proba.html#details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48634762],\n",
       "       [0.46735227],\n",
       "       [0.32571518],\n",
       "       [0.22962177],\n",
       "       [0.17884387],\n",
       "       [0.6300761 ],\n",
       "       [0.01905782],\n",
       "       [0.2839276 ],\n",
       "       [0.90962565],\n",
       "       [0.15771927]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.740\n",
      "roc-auc is 0.810\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x24110a094e0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4372 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7396\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4366 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4363 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4362 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4362 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7396\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4361 - accuracy: 0.7986 - val_loss: 0.5116 - val_accuracy: 0.7396\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.7986 - val_loss: 0.5116 - val_accuracy: 0.7396\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.7986 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4358 - accuracy: 0.7986 - val_loss: 0.5117 - val_accuracy: 0.7396\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.8003 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7986 - val_loss: 0.5118 - val_accuracy: 0.7448\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7986 - val_loss: 0.5118 - val_accuracy: 0.7448\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.7986 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.8003 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.8003 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.8003 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.7986 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.8003 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.8021 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.8003 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.8003 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.8038 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.8038 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.8038 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.8021 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.8021 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.8003 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.8038 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.8056 - val_loss: 0.5118 - val_accuracy: 0.7500\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7500\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.8021 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4334 - accuracy: 0.8021 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4334 - accuracy: 0.8038 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4332 - accuracy: 0.8056 - val_loss: 0.5118 - val_accuracy: 0.7500\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.8021 - val_loss: 0.5118 - val_accuracy: 0.7500\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7500\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4329 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7500\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4328 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7500\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4327 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7500\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4327 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7500\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.8038 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.8038 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.8038 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.8056 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.8038 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.8038 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.8038 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.8038 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.8038 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.8038 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.8038 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.8038 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.8038 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.8038 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.8038 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.8056 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4309 - accuracy: 0.8056 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4307 - accuracy: 0.8038 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.8038 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.8056 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.8038 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.8038 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.8056 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4302 - accuracy: 0.8056 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.8038 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.8056 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.8038 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.8038 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.8056 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.8056 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.8056 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.8056 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8056 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.8056 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.8056 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8056 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.8056 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.8056 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.8056 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.8056 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8056 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4281 - accuracy: 0.8056 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8056 - val_loss: 0.5114 - val_accuracy: 0.7604\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8056 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8056 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8056 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8056 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.8056 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.8056 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.8073 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.8056 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4270 - accuracy: 0.8073 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4269 - accuracy: 0.8090 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.8073 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.8056 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.8090 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.8090 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4266 - accuracy: 0.8090 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4264 - accuracy: 0.8090 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4264 - accuracy: 0.8073 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4262 - accuracy: 0.8073 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.8073 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.8090 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.8090 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.8108 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.8108 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.8090 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.8108 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.8090 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.8090 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.8108 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.8108 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.8090 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.8108 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.8090 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.8090 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4247 - accuracy: 0.8108 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4247 - accuracy: 0.8090 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.8090 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4246 - accuracy: 0.8090 - val_loss: 0.5120 - val_accuracy: 0.7500\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.8090 - val_loss: 0.5120 - val_accuracy: 0.7500\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4243 - accuracy: 0.8090 - val_loss: 0.5120 - val_accuracy: 0.7500\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.8090 - val_loss: 0.5120 - val_accuracy: 0.7500\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.8090 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.8090 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.8090 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.8090 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.8090 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.8090 - val_loss: 0.5122 - val_accuracy: 0.7500\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.8090 - val_loss: 0.5122 - val_accuracy: 0.7500\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.8090 - val_loss: 0.5122 - val_accuracy: 0.7500\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.8090 - val_loss: 0.5122 - val_accuracy: 0.7500\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.8090 - val_loss: 0.5122 - val_accuracy: 0.7500\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.8090 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.8090 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.8090 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.8090 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.8090 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.8090 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.8073 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.8125 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.8090 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.8090 - val_loss: 0.5125 - val_accuracy: 0.7448\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4227 - accuracy: 0.8090 - val_loss: 0.5125 - val_accuracy: 0.7448\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.8090 - val_loss: 0.5125 - val_accuracy: 0.7448\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.8090 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.8108 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8090 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.8108 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.8108 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8108 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8108 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8108 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8125 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8108 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.8108 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.8108 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8125 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8108 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8125 - val_loss: 0.5132 - val_accuracy: 0.7396\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8125 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4215 - accuracy: 0.8108 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8125 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.8125 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.8142 - val_loss: 0.5134 - val_accuracy: 0.7344\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.8142 - val_loss: 0.5135 - val_accuracy: 0.7344\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.8142 - val_loss: 0.5135 - val_accuracy: 0.7344\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.8142 - val_loss: 0.5136 - val_accuracy: 0.7344\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.8142 - val_loss: 0.5136 - val_accuracy: 0.7344\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8160 - val_loss: 0.5136 - val_accuracy: 0.7344\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8142 - val_loss: 0.5137 - val_accuracy: 0.7344\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.8160 - val_loss: 0.5137 - val_accuracy: 0.7344\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.8142 - val_loss: 0.5138 - val_accuracy: 0.7344\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.8160 - val_loss: 0.5138 - val_accuracy: 0.7344\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8142 - val_loss: 0.5138 - val_accuracy: 0.7344\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8142 - val_loss: 0.5139 - val_accuracy: 0.7344\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8160 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8177 - val_loss: 0.5140 - val_accuracy: 0.7344\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.8160 - val_loss: 0.5140 - val_accuracy: 0.7344\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8177 - val_loss: 0.5141 - val_accuracy: 0.7344\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4205 - accuracy: 0.8125 - val_loss: 0.5141 - val_accuracy: 0.7344\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.8177 - val_loss: 0.5141 - val_accuracy: 0.7344\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.8177 - val_loss: 0.5142 - val_accuracy: 0.7344\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.8177 - val_loss: 0.5142 - val_accuracy: 0.7344\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.8177 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.8142 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8177 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8160 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8177 - val_loss: 0.5144 - val_accuracy: 0.7344\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8160 - val_loss: 0.5144 - val_accuracy: 0.7344\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8160 - val_loss: 0.5144 - val_accuracy: 0.7344\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8160 - val_loss: 0.5144 - val_accuracy: 0.7344\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8177 - val_loss: 0.5145 - val_accuracy: 0.7344\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8177 - val_loss: 0.5145 - val_accuracy: 0.7344\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8177 - val_loss: 0.5145 - val_accuracy: 0.7292\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8160 - val_loss: 0.5145 - val_accuracy: 0.7292\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8160 - val_loss: 0.5146 - val_accuracy: 0.7292\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.8177 - val_loss: 0.5146 - val_accuracy: 0.7292\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8177 - val_loss: 0.5146 - val_accuracy: 0.7292\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8142 - val_loss: 0.5146 - val_accuracy: 0.7292\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.8177 - val_loss: 0.5147 - val_accuracy: 0.7292\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4192 - accuracy: 0.8177 - val_loss: 0.5147 - val_accuracy: 0.7292\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8160 - val_loss: 0.5147 - val_accuracy: 0.7292\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8160 - val_loss: 0.5147 - val_accuracy: 0.7292\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8142 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8160 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.8160 - val_loss: 0.5148 - val_accuracy: 0.7292\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.8160 - val_loss: 0.5149 - val_accuracy: 0.7292\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8160 - val_loss: 0.5149 - val_accuracy: 0.7292\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8160 - val_loss: 0.5150 - val_accuracy: 0.7292\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.8177 - val_loss: 0.5150 - val_accuracy: 0.7292\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.8160 - val_loss: 0.5150 - val_accuracy: 0.7292\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8194 - val_loss: 0.5151 - val_accuracy: 0.7292\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.8194 - val_loss: 0.5151 - val_accuracy: 0.7292\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8194 - val_loss: 0.5152 - val_accuracy: 0.7292\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8177 - val_loss: 0.5152 - val_accuracy: 0.7292\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8194 - val_loss: 0.5153 - val_accuracy: 0.7292\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.8194 - val_loss: 0.5153 - val_accuracy: 0.7292\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4183 - accuracy: 0.8212 - val_loss: 0.5153 - val_accuracy: 0.7292\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.8177 - val_loss: 0.5153 - val_accuracy: 0.7292\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.8194 - val_loss: 0.5153 - val_accuracy: 0.7292\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4180 - accuracy: 0.8177 - val_loss: 0.5154 - val_accuracy: 0.7292\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4180 - accuracy: 0.8177 - val_loss: 0.5154 - val_accuracy: 0.7292\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8194 - val_loss: 0.5154 - val_accuracy: 0.7292\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8177 - val_loss: 0.5155 - val_accuracy: 0.7292\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8194 - val_loss: 0.5155 - val_accuracy: 0.7292\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8177 - val_loss: 0.5155 - val_accuracy: 0.7292\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.8194 - val_loss: 0.5156 - val_accuracy: 0.7292\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.8212 - val_loss: 0.5156 - val_accuracy: 0.7344\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8212 - val_loss: 0.5157 - val_accuracy: 0.7344\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8194 - val_loss: 0.5157 - val_accuracy: 0.7344\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.8194 - val_loss: 0.5157 - val_accuracy: 0.7344\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8194 - val_loss: 0.5158 - val_accuracy: 0.7344\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8194 - val_loss: 0.5158 - val_accuracy: 0.7344\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4172 - accuracy: 0.8194 - val_loss: 0.5158 - val_accuracy: 0.7344\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.8194 - val_loss: 0.5159 - val_accuracy: 0.7344\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.8194 - val_loss: 0.5159 - val_accuracy: 0.7344\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.8194 - val_loss: 0.5160 - val_accuracy: 0.7344\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.8194 - val_loss: 0.5161 - val_accuracy: 0.7344\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.8194 - val_loss: 0.5161 - val_accuracy: 0.7396\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8194 - val_loss: 0.5161 - val_accuracy: 0.7396\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.8194 - val_loss: 0.5162 - val_accuracy: 0.7396\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8194 - val_loss: 0.5162 - val_accuracy: 0.7396\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8194 - val_loss: 0.5162 - val_accuracy: 0.7396\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.8194 - val_loss: 0.5163 - val_accuracy: 0.7396\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8194 - val_loss: 0.5163 - val_accuracy: 0.7396\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8194 - val_loss: 0.5164 - val_accuracy: 0.7396\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.8194 - val_loss: 0.5164 - val_accuracy: 0.7396\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.8194 - val_loss: 0.5165 - val_accuracy: 0.7396\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8194 - val_loss: 0.5165 - val_accuracy: 0.7396\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.8194 - val_loss: 0.5166 - val_accuracy: 0.7396\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4164 - accuracy: 0.8194 - val_loss: 0.5166 - val_accuracy: 0.7396\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4162 - accuracy: 0.8194 - val_loss: 0.5166 - val_accuracy: 0.7396\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.8194 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8194 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8194 - val_loss: 0.5168 - val_accuracy: 0.7396\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.8194 - val_loss: 0.5168 - val_accuracy: 0.7344\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8194 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8194 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8194 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8194 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.8194 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.8194 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.8194 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.8194 - val_loss: 0.5172 - val_accuracy: 0.7344\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4157 - accuracy: 0.8194 - val_loss: 0.5172 - val_accuracy: 0.7344\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8194 - val_loss: 0.5173 - val_accuracy: 0.7344\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4155 - accuracy: 0.8194 - val_loss: 0.5173 - val_accuracy: 0.7344\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.8194 - val_loss: 0.5174 - val_accuracy: 0.7344\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.8194 - val_loss: 0.5174 - val_accuracy: 0.7344\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8194 - val_loss: 0.5175 - val_accuracy: 0.7344\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8194 - val_loss: 0.5175 - val_accuracy: 0.7344\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.8194 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8194 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.8194 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.8194 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.8194 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.8194 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.8177 - val_loss: 0.5178 - val_accuracy: 0.7396\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8177 - val_loss: 0.5178 - val_accuracy: 0.7396\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8194 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.8194 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8177 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8194 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4146 - accuracy: 0.8194 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8177 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.8194 - val_loss: 0.5181 - val_accuracy: 0.7396\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8194 - val_loss: 0.5182 - val_accuracy: 0.7396\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8177 - val_loss: 0.5182 - val_accuracy: 0.7396\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4144 - accuracy: 0.8194 - val_loss: 0.5182 - val_accuracy: 0.7396\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8177 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8160 - val_loss: 0.5184 - val_accuracy: 0.7396\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.8194 - val_loss: 0.5184 - val_accuracy: 0.7396\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8160 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8160 - val_loss: 0.5185 - val_accuracy: 0.7396\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8177 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8177 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.8160 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4139 - accuracy: 0.8160 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.8160 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.8160 - val_loss: 0.5188 - val_accuracy: 0.7396\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.8177 - val_loss: 0.5188 - val_accuracy: 0.7396\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8177 - val_loss: 0.5189 - val_accuracy: 0.7396\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4137 - accuracy: 0.8177 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8194 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8142 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.8177 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.8194 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.8194 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8177 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8177 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8177 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.8160 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4131 - accuracy: 0.8177 - val_loss: 0.5195 - val_accuracy: 0.7344\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8160 - val_loss: 0.5195 - val_accuracy: 0.7344\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4130 - accuracy: 0.8177 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8142 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8142 - val_loss: 0.5198 - val_accuracy: 0.7344\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8177 - val_loss: 0.5199 - val_accuracy: 0.7344\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8142 - val_loss: 0.5200 - val_accuracy: 0.7344\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.8160 - val_loss: 0.5201 - val_accuracy: 0.7344\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.8125 - val_loss: 0.5202 - val_accuracy: 0.7344\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.8142 - val_loss: 0.5203 - val_accuracy: 0.7344\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.8125 - val_loss: 0.5204 - val_accuracy: 0.7344\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8160 - val_loss: 0.5205 - val_accuracy: 0.7344\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8142 - val_loss: 0.5206 - val_accuracy: 0.7344\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8142 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8142 - val_loss: 0.5208 - val_accuracy: 0.7344\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8160 - val_loss: 0.5208 - val_accuracy: 0.7344\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8125 - val_loss: 0.5209 - val_accuracy: 0.7344\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8142 - val_loss: 0.5210 - val_accuracy: 0.7344\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.8142 - val_loss: 0.5210 - val_accuracy: 0.7344\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4121 - accuracy: 0.8160 - val_loss: 0.5211 - val_accuracy: 0.7344\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8142 - val_loss: 0.5212 - val_accuracy: 0.7344\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8142 - val_loss: 0.5213 - val_accuracy: 0.7344\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8125 - val_loss: 0.5214 - val_accuracy: 0.7344\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8142 - val_loss: 0.5214 - val_accuracy: 0.7344\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8142 - val_loss: 0.5215 - val_accuracy: 0.7344\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8142 - val_loss: 0.5216 - val_accuracy: 0.7344\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8142 - val_loss: 0.5217 - val_accuracy: 0.7344\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8160 - val_loss: 0.5217 - val_accuracy: 0.7344\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8160 - val_loss: 0.5218 - val_accuracy: 0.7344\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8160 - val_loss: 0.5219 - val_accuracy: 0.7344\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8142 - val_loss: 0.5219 - val_accuracy: 0.7344\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8142 - val_loss: 0.5220 - val_accuracy: 0.7344\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4115 - accuracy: 0.8160 - val_loss: 0.5221 - val_accuracy: 0.7344\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.8142 - val_loss: 0.5222 - val_accuracy: 0.7344\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8142 - val_loss: 0.5222 - val_accuracy: 0.7344\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.8142 - val_loss: 0.5223 - val_accuracy: 0.7344\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8142 - val_loss: 0.5224 - val_accuracy: 0.7344\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8160 - val_loss: 0.5225 - val_accuracy: 0.7344\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8160 - val_loss: 0.5225 - val_accuracy: 0.7344\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8142 - val_loss: 0.5226 - val_accuracy: 0.7344\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8142 - val_loss: 0.5226 - val_accuracy: 0.7344\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8160 - val_loss: 0.5227 - val_accuracy: 0.7344\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8160 - val_loss: 0.5228 - val_accuracy: 0.7344\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8194 - val_loss: 0.5229 - val_accuracy: 0.7344\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8160 - val_loss: 0.5229 - val_accuracy: 0.7344\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8142 - val_loss: 0.5230 - val_accuracy: 0.7344\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8142 - val_loss: 0.5231 - val_accuracy: 0.7344\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8177 - val_loss: 0.5232 - val_accuracy: 0.7344\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4108 - accuracy: 0.8160 - val_loss: 0.5232 - val_accuracy: 0.7344\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8160 - val_loss: 0.5233 - val_accuracy: 0.7344\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8160 - val_loss: 0.5233 - val_accuracy: 0.7344\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8160 - val_loss: 0.5234 - val_accuracy: 0.7344\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8177 - val_loss: 0.5235 - val_accuracy: 0.7344\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8160 - val_loss: 0.5235 - val_accuracy: 0.7344\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8160 - val_loss: 0.5236 - val_accuracy: 0.7344\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8160 - val_loss: 0.5236 - val_accuracy: 0.7344\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8177 - val_loss: 0.5237 - val_accuracy: 0.7344\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8160 - val_loss: 0.5238 - val_accuracy: 0.7344\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8177 - val_loss: 0.5238 - val_accuracy: 0.7344\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8160 - val_loss: 0.5238 - val_accuracy: 0.7344\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8194 - val_loss: 0.5239 - val_accuracy: 0.7344\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8160 - val_loss: 0.5240 - val_accuracy: 0.7344\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8177 - val_loss: 0.5241 - val_accuracy: 0.7344\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4104 - accuracy: 0.8194 - val_loss: 0.5242 - val_accuracy: 0.7344\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8177 - val_loss: 0.5242 - val_accuracy: 0.7344\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8177 - val_loss: 0.5243 - val_accuracy: 0.7344\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8160 - val_loss: 0.5243 - val_accuracy: 0.7344\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.8194 - val_loss: 0.5244 - val_accuracy: 0.7344\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8177 - val_loss: 0.5244 - val_accuracy: 0.7344\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8177 - val_loss: 0.5244 - val_accuracy: 0.7344\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8177 - val_loss: 0.5245 - val_accuracy: 0.7344\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4102 - accuracy: 0.8194 - val_loss: 0.5245 - val_accuracy: 0.7344\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8177 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8194 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4100 - accuracy: 0.8194 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8194 - val_loss: 0.5247 - val_accuracy: 0.7344\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4100 - accuracy: 0.8194 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4099 - accuracy: 0.8160 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.8194 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8177 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8177 - val_loss: 0.5249 - val_accuracy: 0.7344\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8177 - val_loss: 0.5250 - val_accuracy: 0.7344\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8194 - val_loss: 0.5250 - val_accuracy: 0.7344\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8160 - val_loss: 0.5250 - val_accuracy: 0.7344\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8194 - val_loss: 0.5251 - val_accuracy: 0.7344\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8194 - val_loss: 0.5251 - val_accuracy: 0.7344\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8194 - val_loss: 0.5252 - val_accuracy: 0.7344\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8194 - val_loss: 0.5252 - val_accuracy: 0.7344\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8194 - val_loss: 0.5253 - val_accuracy: 0.7344\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8194 - val_loss: 0.5254 - val_accuracy: 0.7344\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4095 - accuracy: 0.8212 - val_loss: 0.5255 - val_accuracy: 0.7344\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8212 - val_loss: 0.5255 - val_accuracy: 0.7344\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8177 - val_loss: 0.5255 - val_accuracy: 0.7344\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8177 - val_loss: 0.5256 - val_accuracy: 0.7344\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8194 - val_loss: 0.5256 - val_accuracy: 0.7344\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8177 - val_loss: 0.5256 - val_accuracy: 0.7344\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8177 - val_loss: 0.5257 - val_accuracy: 0.7344\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8194 - val_loss: 0.5257 - val_accuracy: 0.7344\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4092 - accuracy: 0.8212 - val_loss: 0.5258 - val_accuracy: 0.7344\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8212 - val_loss: 0.5258 - val_accuracy: 0.7344\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.8194 - val_loss: 0.5259 - val_accuracy: 0.7344\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.8194 - val_loss: 0.5259 - val_accuracy: 0.7344\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4090 - accuracy: 0.8212 - val_loss: 0.5259 - val_accuracy: 0.7344\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8194 - val_loss: 0.5260 - val_accuracy: 0.7344\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8212 - val_loss: 0.5260 - val_accuracy: 0.7344\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8194 - val_loss: 0.5260 - val_accuracy: 0.7344\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8229 - val_loss: 0.5261 - val_accuracy: 0.7344\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8212 - val_loss: 0.5262 - val_accuracy: 0.7344\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8194 - val_loss: 0.5262 - val_accuracy: 0.7344\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8194 - val_loss: 0.5263 - val_accuracy: 0.7344\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8194 - val_loss: 0.5263 - val_accuracy: 0.7344\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8194 - val_loss: 0.5264 - val_accuracy: 0.7344\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8212 - val_loss: 0.5264 - val_accuracy: 0.7344\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8212 - val_loss: 0.5264 - val_accuracy: 0.7344\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8229 - val_loss: 0.5265 - val_accuracy: 0.7344\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8212 - val_loss: 0.5266 - val_accuracy: 0.7344\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4086 - accuracy: 0.8212 - val_loss: 0.5266 - val_accuracy: 0.7344\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8212 - val_loss: 0.5266 - val_accuracy: 0.7344\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8212 - val_loss: 0.5267 - val_accuracy: 0.7344\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4086 - accuracy: 0.8212 - val_loss: 0.5267 - val_accuracy: 0.7344\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8229 - val_loss: 0.5268 - val_accuracy: 0.7344\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8212 - val_loss: 0.5268 - val_accuracy: 0.7292\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8229 - val_loss: 0.5268 - val_accuracy: 0.7292\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8212 - val_loss: 0.5269 - val_accuracy: 0.7292\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8229 - val_loss: 0.5270 - val_accuracy: 0.7292\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.8229 - val_loss: 0.5270 - val_accuracy: 0.7292\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8229 - val_loss: 0.5270 - val_accuracy: 0.7292\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.8194 - val_loss: 0.5270 - val_accuracy: 0.7292\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8229 - val_loss: 0.5271 - val_accuracy: 0.7292\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8229 - val_loss: 0.5271 - val_accuracy: 0.7292\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4083 - accuracy: 0.8229 - val_loss: 0.5271 - val_accuracy: 0.7292\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8212 - val_loss: 0.5272 - val_accuracy: 0.7292\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8229 - val_loss: 0.5272 - val_accuracy: 0.7292\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8229 - val_loss: 0.5272 - val_accuracy: 0.7292\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8229 - val_loss: 0.5273 - val_accuracy: 0.7292\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8229 - val_loss: 0.5274 - val_accuracy: 0.7292\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8229 - val_loss: 0.5274 - val_accuracy: 0.7292\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8229 - val_loss: 0.5275 - val_accuracy: 0.7292\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8229 - val_loss: 0.5275 - val_accuracy: 0.7292\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8229 - val_loss: 0.5275 - val_accuracy: 0.7292\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8229 - val_loss: 0.5275 - val_accuracy: 0.7292\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8229 - val_loss: 0.5276 - val_accuracy: 0.7292\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8229 - val_loss: 0.5276 - val_accuracy: 0.7292\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4079 - accuracy: 0.8229 - val_loss: 0.5276 - val_accuracy: 0.7292\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8229 - val_loss: 0.5277 - val_accuracy: 0.7292\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8229 - val_loss: 0.5277 - val_accuracy: 0.7292\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8229 - val_loss: 0.5277 - val_accuracy: 0.7292\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8229 - val_loss: 0.5278 - val_accuracy: 0.7292\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8229 - val_loss: 0.5278 - val_accuracy: 0.7292\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8229 - val_loss: 0.5279 - val_accuracy: 0.7292\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8229 - val_loss: 0.5279 - val_accuracy: 0.7292\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8229 - val_loss: 0.5279 - val_accuracy: 0.7292\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8229 - val_loss: 0.5280 - val_accuracy: 0.7344\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8229 - val_loss: 0.5280 - val_accuracy: 0.7344\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8229 - val_loss: 0.5280 - val_accuracy: 0.7344\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8229 - val_loss: 0.5281 - val_accuracy: 0.7344\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4076 - accuracy: 0.8229 - val_loss: 0.5281 - val_accuracy: 0.7344\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8229 - val_loss: 0.5282 - val_accuracy: 0.7344\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8229 - val_loss: 0.5282 - val_accuracy: 0.7344\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8229 - val_loss: 0.5282 - val_accuracy: 0.7344\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8229 - val_loss: 0.5282 - val_accuracy: 0.7344\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8229 - val_loss: 0.5283 - val_accuracy: 0.7344\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8229 - val_loss: 0.5283 - val_accuracy: 0.7396\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8229 - val_loss: 0.5284 - val_accuracy: 0.7396\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8229 - val_loss: 0.5284 - val_accuracy: 0.7396\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8229 - val_loss: 0.5285 - val_accuracy: 0.7396\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8247 - val_loss: 0.5285 - val_accuracy: 0.7396\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8229 - val_loss: 0.5285 - val_accuracy: 0.7396\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4073 - accuracy: 0.8229 - val_loss: 0.5286 - val_accuracy: 0.7396\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8229 - val_loss: 0.5287 - val_accuracy: 0.7396\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8229 - val_loss: 0.5287 - val_accuracy: 0.7396\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8229 - val_loss: 0.5288 - val_accuracy: 0.7396\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8229 - val_loss: 0.5288 - val_accuracy: 0.7396\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8229 - val_loss: 0.5288 - val_accuracy: 0.7396\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8229 - val_loss: 0.5289 - val_accuracy: 0.7396\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8229 - val_loss: 0.5289 - val_accuracy: 0.7396\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8229 - val_loss: 0.5289 - val_accuracy: 0.7396\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8229 - val_loss: 0.5289 - val_accuracy: 0.7396\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8229 - val_loss: 0.5290 - val_accuracy: 0.7396\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4071 - accuracy: 0.8229 - val_loss: 0.5290 - val_accuracy: 0.7396\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8229 - val_loss: 0.5291 - val_accuracy: 0.7396\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8229 - val_loss: 0.5291 - val_accuracy: 0.7396\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8229 - val_loss: 0.5292 - val_accuracy: 0.7396\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8212 - val_loss: 0.5292 - val_accuracy: 0.7396\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8229 - val_loss: 0.5293 - val_accuracy: 0.7396\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8229 - val_loss: 0.5293 - val_accuracy: 0.7396\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8247 - val_loss: 0.5293 - val_accuracy: 0.7396\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8212 - val_loss: 0.5294 - val_accuracy: 0.7396\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8229 - val_loss: 0.5295 - val_accuracy: 0.7396\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8229 - val_loss: 0.5295 - val_accuracy: 0.7396\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4069 - accuracy: 0.8229 - val_loss: 0.5296 - val_accuracy: 0.7396\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8229 - val_loss: 0.5296 - val_accuracy: 0.7396\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8229 - val_loss: 0.5297 - val_accuracy: 0.7396\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8229 - val_loss: 0.5297 - val_accuracy: 0.7396\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8229 - val_loss: 0.5297 - val_accuracy: 0.7396\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8229 - val_loss: 0.5297 - val_accuracy: 0.7396\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8229 - val_loss: 0.5298 - val_accuracy: 0.7396\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8229 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8229 - val_loss: 0.5299 - val_accuracy: 0.7344\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8229 - val_loss: 0.5300 - val_accuracy: 0.7344\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8229 - val_loss: 0.5300 - val_accuracy: 0.7344\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8212 - val_loss: 0.5301 - val_accuracy: 0.7344\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.8229 - val_loss: 0.5302 - val_accuracy: 0.7344\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8212 - val_loss: 0.5302 - val_accuracy: 0.7344\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8212 - val_loss: 0.5303 - val_accuracy: 0.7344\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8229 - val_loss: 0.5304 - val_accuracy: 0.7344\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8229 - val_loss: 0.5304 - val_accuracy: 0.7344\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8229 - val_loss: 0.5304 - val_accuracy: 0.7344\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8229 - val_loss: 0.5305 - val_accuracy: 0.7344\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8229 - val_loss: 0.5305 - val_accuracy: 0.7344\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8247 - val_loss: 0.5306 - val_accuracy: 0.7344\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8229 - val_loss: 0.5307 - val_accuracy: 0.7344\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8229 - val_loss: 0.5308 - val_accuracy: 0.7344\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8229 - val_loss: 0.5308 - val_accuracy: 0.7344\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.8247 - val_loss: 0.5308 - val_accuracy: 0.7344\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8229 - val_loss: 0.5309 - val_accuracy: 0.7344\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8194 - val_loss: 0.5310 - val_accuracy: 0.7344\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8229 - val_loss: 0.5310 - val_accuracy: 0.7344\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8229 - val_loss: 0.5311 - val_accuracy: 0.7344\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8194 - val_loss: 0.5311 - val_accuracy: 0.7344\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8247 - val_loss: 0.5312 - val_accuracy: 0.7344\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8247 - val_loss: 0.5312 - val_accuracy: 0.7344\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8212 - val_loss: 0.5312 - val_accuracy: 0.7344\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8212 - val_loss: 0.5312 - val_accuracy: 0.7344\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8264 - val_loss: 0.5313 - val_accuracy: 0.7344\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4061 - accuracy: 0.8229 - val_loss: 0.5313 - val_accuracy: 0.7344\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8212 - val_loss: 0.5314 - val_accuracy: 0.7344\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8247 - val_loss: 0.5315 - val_accuracy: 0.7344\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8247 - val_loss: 0.5315 - val_accuracy: 0.7344\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8229 - val_loss: 0.5315 - val_accuracy: 0.7344\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8264 - val_loss: 0.5316 - val_accuracy: 0.7344\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8264 - val_loss: 0.5316 - val_accuracy: 0.7344\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8247 - val_loss: 0.5317 - val_accuracy: 0.7344\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8247 - val_loss: 0.5318 - val_accuracy: 0.7344\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8194 - val_loss: 0.5319 - val_accuracy: 0.7344\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8247 - val_loss: 0.5319 - val_accuracy: 0.7344\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4059 - accuracy: 0.8194 - val_loss: 0.5320 - val_accuracy: 0.7344\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8247 - val_loss: 0.5320 - val_accuracy: 0.7344\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8264 - val_loss: 0.5321 - val_accuracy: 0.7344\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8212 - val_loss: 0.5321 - val_accuracy: 0.7344\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8212 - val_loss: 0.5322 - val_accuracy: 0.7344\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8247 - val_loss: 0.5323 - val_accuracy: 0.7344\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8229 - val_loss: 0.5324 - val_accuracy: 0.7344\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.8194 - val_loss: 0.5324 - val_accuracy: 0.7344\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.8247 - val_loss: 0.5325 - val_accuracy: 0.7344\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.8212 - val_loss: 0.5325 - val_accuracy: 0.7344\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.8229 - val_loss: 0.5325 - val_accuracy: 0.7344\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8247 - val_loss: 0.5326 - val_accuracy: 0.7344\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8247 - val_loss: 0.5326 - val_accuracy: 0.7344\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8264 - val_loss: 0.5327 - val_accuracy: 0.7344\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8194 - val_loss: 0.5327 - val_accuracy: 0.7344\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.8212 - val_loss: 0.5328 - val_accuracy: 0.7344\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4055 - accuracy: 0.8247 - val_loss: 0.5328 - val_accuracy: 0.7344\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8229 - val_loss: 0.5329 - val_accuracy: 0.7344\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8212 - val_loss: 0.5329 - val_accuracy: 0.7344\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8212 - val_loss: 0.5329 - val_accuracy: 0.7344\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8194 - val_loss: 0.5330 - val_accuracy: 0.7344\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8212 - val_loss: 0.5330 - val_accuracy: 0.7344\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8194 - val_loss: 0.5331 - val_accuracy: 0.7344\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.8229 - val_loss: 0.5331 - val_accuracy: 0.7344\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8212 - val_loss: 0.5332 - val_accuracy: 0.7344\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8194 - val_loss: 0.5332 - val_accuracy: 0.7344\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.8194 - val_loss: 0.5332 - val_accuracy: 0.7344\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4053 - accuracy: 0.8194 - val_loss: 0.5333 - val_accuracy: 0.7344\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8212 - val_loss: 0.5333 - val_accuracy: 0.7344\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.8194 - val_loss: 0.5333 - val_accuracy: 0.7344\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.8212 - val_loss: 0.5334 - val_accuracy: 0.7344\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.8194 - val_loss: 0.5334 - val_accuracy: 0.7344\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.8212 - val_loss: 0.5334 - val_accuracy: 0.7292\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.8194 - val_loss: 0.5334 - val_accuracy: 0.7292\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8194 - val_loss: 0.5335 - val_accuracy: 0.7344\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8212 - val_loss: 0.5336 - val_accuracy: 0.7292\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8212 - val_loss: 0.5336 - val_accuracy: 0.7344\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8212 - val_loss: 0.5336 - val_accuracy: 0.7344\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4051 - accuracy: 0.8194 - val_loss: 0.5336 - val_accuracy: 0.7344\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8194 - val_loss: 0.5336 - val_accuracy: 0.7344\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8194 - val_loss: 0.5337 - val_accuracy: 0.7344\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4049 - accuracy: 0.8212 - val_loss: 0.5337 - val_accuracy: 0.7344\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8212 - val_loss: 0.5338 - val_accuracy: 0.7344\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4049 - accuracy: 0.8194 - val_loss: 0.5338 - val_accuracy: 0.7344\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4049 - accuracy: 0.8212 - val_loss: 0.5339 - val_accuracy: 0.7344\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8212 - val_loss: 0.5339 - val_accuracy: 0.7344\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8194 - val_loss: 0.5339 - val_accuracy: 0.7292\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8212 - val_loss: 0.5340 - val_accuracy: 0.7292\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4049 - accuracy: 0.8194 - val_loss: 0.5340 - val_accuracy: 0.7292\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4048 - accuracy: 0.8194 - val_loss: 0.5341 - val_accuracy: 0.7292\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8212 - val_loss: 0.5341 - val_accuracy: 0.7344\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8212 - val_loss: 0.5341 - val_accuracy: 0.7292\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8212 - val_loss: 0.5341 - val_accuracy: 0.7292\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.8212 - val_loss: 0.5342 - val_accuracy: 0.7344\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8212 - val_loss: 0.5342 - val_accuracy: 0.7344\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4047 - accuracy: 0.8212 - val_loss: 0.5343 - val_accuracy: 0.7292\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8229 - val_loss: 0.5343 - val_accuracy: 0.7292\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8194 - val_loss: 0.5344 - val_accuracy: 0.7240\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8194 - val_loss: 0.5344 - val_accuracy: 0.7240\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8194 - val_loss: 0.5344 - val_accuracy: 0.7240\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4046 - accuracy: 0.8194 - val_loss: 0.5344 - val_accuracy: 0.7240\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8194 - val_loss: 0.5345 - val_accuracy: 0.7240\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8212 - val_loss: 0.5345 - val_accuracy: 0.7240\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8194 - val_loss: 0.5346 - val_accuracy: 0.7240\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8194 - val_loss: 0.5346 - val_accuracy: 0.7240\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8194 - val_loss: 0.5347 - val_accuracy: 0.7240\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.8212 - val_loss: 0.5347 - val_accuracy: 0.7240\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8212 - val_loss: 0.5348 - val_accuracy: 0.7240\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8194 - val_loss: 0.5348 - val_accuracy: 0.7240\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8212 - val_loss: 0.5348 - val_accuracy: 0.7240\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4045 - accuracy: 0.8212 - val_loss: 0.5348 - val_accuracy: 0.7240\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8194 - val_loss: 0.5349 - val_accuracy: 0.7292\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8194 - val_loss: 0.5349 - val_accuracy: 0.7292\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8212 - val_loss: 0.5350 - val_accuracy: 0.7292\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8212 - val_loss: 0.5350 - val_accuracy: 0.7240\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8212 - val_loss: 0.5351 - val_accuracy: 0.7240\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8212 - val_loss: 0.5351 - val_accuracy: 0.7240\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8212 - val_loss: 0.5351 - val_accuracy: 0.7292\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8212 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8212 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8212 - val_loss: 0.5352 - val_accuracy: 0.7292\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4043 - accuracy: 0.8229 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8194 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4043 - accuracy: 0.8229 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8194 - val_loss: 0.5354 - val_accuracy: 0.7292\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8212 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8212 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8194 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8212 - val_loss: 0.5355 - val_accuracy: 0.7240\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8212 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4043 - accuracy: 0.8212 - val_loss: 0.5355 - val_accuracy: 0.7240\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4042 - accuracy: 0.8212 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8212 - val_loss: 0.5356 - val_accuracy: 0.7240\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8229 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8194 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8212 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8229 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8194 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4041 - accuracy: 0.8229 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4041 - accuracy: 0.8212 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.8212 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4040 - accuracy: 0.8194 - val_loss: 0.5359 - val_accuracy: 0.7240\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.8194 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8229 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8212 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8194 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8229 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8212 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.8212 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.8229 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8229 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4039 - accuracy: 0.8212 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8212 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8212 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8212 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8212 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8229 - val_loss: 0.5362 - val_accuracy: 0.7240\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8229 - val_loss: 0.5362 - val_accuracy: 0.7240\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8229 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8229 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8229 - val_loss: 0.5363 - val_accuracy: 0.7292\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4038 - accuracy: 0.8212 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8212 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8229 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8229 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8212 - val_loss: 0.5364 - val_accuracy: 0.7292\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8212 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8212 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8212 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8194 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8212 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4036 - accuracy: 0.8229 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4036 - accuracy: 0.8194 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8229 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8212 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8212 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8229 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8212 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8212 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8212 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8212 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.8247 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4035 - accuracy: 0.8194 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4034 - accuracy: 0.8212 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8229 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8194 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8229 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8212 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8194 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8229 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4033 - accuracy: 0.8212 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8229 - val_loss: 0.5368 - val_accuracy: 0.7292\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8229 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8229 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8247 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8229 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4032 - accuracy: 0.8229 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8247 - val_loss: 0.5369 - val_accuracy: 0.7292\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8229 - val_loss: 0.5370 - val_accuracy: 0.7292\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8229 - val_loss: 0.5370 - val_accuracy: 0.7292\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8229 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8229 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8229 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8229 - val_loss: 0.5371 - val_accuracy: 0.7292\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8229 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8229 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8229 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8247 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4029 - accuracy: 0.8247 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8229 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8229 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8229 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8247 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8247 - val_loss: 0.5372 - val_accuracy: 0.7292\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8229 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8212 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8247 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8229 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.8247 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4027 - accuracy: 0.8247 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8229 - val_loss: 0.5374 - val_accuracy: 0.7292\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8247 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8229 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8247 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8247 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8247 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8247 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.8229 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4027 - accuracy: 0.8247 - val_loss: 0.5375 - val_accuracy: 0.7240\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.8247 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.8229 - val_loss: 0.5375 - val_accuracy: 0.7240\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.8247 - val_loss: 0.5375 - val_accuracy: 0.7240\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.8229 - val_loss: 0.5376 - val_accuracy: 0.7240\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8229 - val_loss: 0.5376 - val_accuracy: 0.7292\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.8247 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8229 - val_loss: 0.5377 - val_accuracy: 0.7240\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4026 - accuracy: 0.8247 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8247 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.8212 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8264 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8247 - val_loss: 0.5378 - val_accuracy: 0.7240\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8212 - val_loss: 0.5378 - val_accuracy: 0.7292\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8264 - val_loss: 0.5378 - val_accuracy: 0.7292\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8247 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8247 - val_loss: 0.5377 - val_accuracy: 0.7292\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4024 - accuracy: 0.8264 - val_loss: 0.5378 - val_accuracy: 0.7292\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.8229 - val_loss: 0.5378 - val_accuracy: 0.7292\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8247 - val_loss: 0.5378 - val_accuracy: 0.7292\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8247 - val_loss: 0.5378 - val_accuracy: 0.7292\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8247 - val_loss: 0.5378 - val_accuracy: 0.7292\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.8247 - val_loss: 0.5378 - val_accuracy: 0.7292\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8247 - val_loss: 0.5379 - val_accuracy: 0.7240\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8264 - val_loss: 0.5379 - val_accuracy: 0.7292\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8247 - val_loss: 0.5379 - val_accuracy: 0.7292\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4023 - accuracy: 0.8247 - val_loss: 0.5379 - val_accuracy: 0.7292\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4023 - accuracy: 0.8247 - val_loss: 0.5379 - val_accuracy: 0.7292\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4022 - accuracy: 0.8264 - val_loss: 0.5379 - val_accuracy: 0.7292\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4023 - accuracy: 0.8212 - val_loss: 0.5380 - val_accuracy: 0.7292\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4022 - accuracy: 0.8247 - val_loss: 0.5380 - val_accuracy: 0.7292\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8247 - val_loss: 0.5379 - val_accuracy: 0.7292\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8247 - val_loss: 0.5379 - val_accuracy: 0.7292\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4022 - accuracy: 0.8247 - val_loss: 0.5380 - val_accuracy: 0.7292\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4022 - accuracy: 0.8229 - val_loss: 0.5380 - val_accuracy: 0.7292\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4023 - accuracy: 0.8264 - val_loss: 0.5380 - val_accuracy: 0.7292\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8229 - val_loss: 0.5380 - val_accuracy: 0.7292\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8212 - val_loss: 0.5381 - val_accuracy: 0.7292\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8229 - val_loss: 0.5380 - val_accuracy: 0.7292\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8229 - val_loss: 0.5380 - val_accuracy: 0.7292\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.8229 - val_loss: 0.5380 - val_accuracy: 0.7292\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4020 - accuracy: 0.8247 - val_loss: 0.5380 - val_accuracy: 0.7240\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8264 - val_loss: 0.5381 - val_accuracy: 0.7292\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8247 - val_loss: 0.5381 - val_accuracy: 0.7292\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8247 - val_loss: 0.5381 - val_accuracy: 0.7240\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4020 - accuracy: 0.8229 - val_loss: 0.5381 - val_accuracy: 0.7292\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8247 - val_loss: 0.5382 - val_accuracy: 0.7240\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8229 - val_loss: 0.5381 - val_accuracy: 0.7292\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8247 - val_loss: 0.5381 - val_accuracy: 0.7292\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8247 - val_loss: 0.5381 - val_accuracy: 0.7292\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8247 - val_loss: 0.5381 - val_accuracy: 0.7292\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8247 - val_loss: 0.5381 - val_accuracy: 0.7292\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4018 - accuracy: 0.8247 - val_loss: 0.5381 - val_accuracy: 0.7292\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4019 - accuracy: 0.8229 - val_loss: 0.5382 - val_accuracy: 0.7240\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8264 - val_loss: 0.5382 - val_accuracy: 0.7240\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8264 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8264 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8264 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.8264 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8264 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.8247 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4018 - accuracy: 0.8264 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.8264 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.8281 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8281 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8264 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4017 - accuracy: 0.8264 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.8247 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8264 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4016 - accuracy: 0.8264 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4015 - accuracy: 0.8264 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.8281 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.8281 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4015 - accuracy: 0.8281 - val_loss: 0.5385 - val_accuracy: 0.7240\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.8264 - val_loss: 0.5385 - val_accuracy: 0.7240\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.8281 - val_loss: 0.5385 - val_accuracy: 0.7240\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.8264 - val_loss: 0.5385 - val_accuracy: 0.7240\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.8281 - val_loss: 0.5386 - val_accuracy: 0.7240\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.8281 - val_loss: 0.5386 - val_accuracy: 0.7240\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.8281 - val_loss: 0.5385 - val_accuracy: 0.7240\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.8281 - val_loss: 0.5386 - val_accuracy: 0.7240\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4013 - accuracy: 0.8264 - val_loss: 0.5385 - val_accuracy: 0.7240\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.8281 - val_loss: 0.5386 - val_accuracy: 0.7240\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.8281 - val_loss: 0.5386 - val_accuracy: 0.7240\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.8281 - val_loss: 0.5387 - val_accuracy: 0.7240\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8281 - val_loss: 0.5387 - val_accuracy: 0.7240\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.8281 - val_loss: 0.5387 - val_accuracy: 0.7240\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8281 - val_loss: 0.5387 - val_accuracy: 0.7240\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.8281 - val_loss: 0.5388 - val_accuracy: 0.7240\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.8281 - val_loss: 0.5387 - val_accuracy: 0.7240\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.8281 - val_loss: 0.5387 - val_accuracy: 0.7240\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.8281 - val_loss: 0.5387 - val_accuracy: 0.7240\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.8281 - val_loss: 0.5388 - val_accuracy: 0.7292\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4012 - accuracy: 0.8281 - val_loss: 0.5388 - val_accuracy: 0.7240\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.8281 - val_loss: 0.5388 - val_accuracy: 0.7240\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4012 - accuracy: 0.8281 - val_loss: 0.5388 - val_accuracy: 0.7240\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.8281 - val_loss: 0.5388 - val_accuracy: 0.7240\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.8281 - val_loss: 0.5388 - val_accuracy: 0.7240\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.8281 - val_loss: 0.5389 - val_accuracy: 0.7292\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.8281 - val_loss: 0.5389 - val_accuracy: 0.7292\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.8281 - val_loss: 0.5389 - val_accuracy: 0.7292\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4011 - accuracy: 0.8281 - val_loss: 0.5389 - val_accuracy: 0.7292\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8281 - val_loss: 0.5389 - val_accuracy: 0.7292\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4011 - accuracy: 0.8281 - val_loss: 0.5390 - val_accuracy: 0.7292\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4009 - accuracy: 0.8281 - val_loss: 0.5390 - val_accuracy: 0.7292\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8281 - val_loss: 0.5389 - val_accuracy: 0.7292\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4009 - accuracy: 0.8281 - val_loss: 0.5390 - val_accuracy: 0.7292\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4009 - accuracy: 0.8281 - val_loss: 0.5389 - val_accuracy: 0.7292\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4009 - accuracy: 0.8281 - val_loss: 0.5389 - val_accuracy: 0.7292\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8281 - val_loss: 0.5390 - val_accuracy: 0.7292\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.8281 - val_loss: 0.5390 - val_accuracy: 0.7292\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.8281 - val_loss: 0.5390 - val_accuracy: 0.7292\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4008 - accuracy: 0.8264 - val_loss: 0.5390 - val_accuracy: 0.7292\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4008 - accuracy: 0.8281 - val_loss: 0.5390 - val_accuracy: 0.7292\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.8281 - val_loss: 0.5390 - val_accuracy: 0.7292\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4008 - accuracy: 0.8264 - val_loss: 0.5389 - val_accuracy: 0.7292\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4008 - accuracy: 0.8281 - val_loss: 0.5391 - val_accuracy: 0.7292\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4007 - accuracy: 0.8281 - val_loss: 0.5390 - val_accuracy: 0.7292\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4008 - accuracy: 0.8281 - val_loss: 0.5391 - val_accuracy: 0.7292\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.8281 - val_loss: 0.5391 - val_accuracy: 0.7292\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.8281 - val_loss: 0.5392 - val_accuracy: 0.7292\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8281 - val_loss: 0.5391 - val_accuracy: 0.7292\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4008 - accuracy: 0.8281 - val_loss: 0.5391 - val_accuracy: 0.7292\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.8264 - val_loss: 0.5390 - val_accuracy: 0.7292\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8281 - val_loss: 0.5391 - val_accuracy: 0.7292\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.8281 - val_loss: 0.5391 - val_accuracy: 0.7292\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8281 - val_loss: 0.5391 - val_accuracy: 0.7292\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8264 - val_loss: 0.5391 - val_accuracy: 0.7292\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.8281 - val_loss: 0.5392 - val_accuracy: 0.7292\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8281 - val_loss: 0.5392 - val_accuracy: 0.7292\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4005 - accuracy: 0.8281 - val_loss: 0.5393 - val_accuracy: 0.7292\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8281 - val_loss: 0.5393 - val_accuracy: 0.7292\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8281 - val_loss: 0.5392 - val_accuracy: 0.7292\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8281 - val_loss: 0.5393 - val_accuracy: 0.7292\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8281 - val_loss: 0.5392 - val_accuracy: 0.7292\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8264 - val_loss: 0.5393 - val_accuracy: 0.7292\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8281 - val_loss: 0.5393 - val_accuracy: 0.7292\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8264 - val_loss: 0.5394 - val_accuracy: 0.7292\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4003 - accuracy: 0.8281 - val_loss: 0.5394 - val_accuracy: 0.7292\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.8281 - val_loss: 0.5394 - val_accuracy: 0.7292\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8281 - val_loss: 0.5395 - val_accuracy: 0.7292\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8264 - val_loss: 0.5395 - val_accuracy: 0.7292\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8264 - val_loss: 0.5395 - val_accuracy: 0.7292\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.8247 - val_loss: 0.5395 - val_accuracy: 0.7292\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8281 - val_loss: 0.5395 - val_accuracy: 0.7292\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8264 - val_loss: 0.5395 - val_accuracy: 0.7292\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4000 - accuracy: 0.8264 - val_loss: 0.5395 - val_accuracy: 0.7292\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8264 - val_loss: 0.5395 - val_accuracy: 0.7344\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8264 - val_loss: 0.5396 - val_accuracy: 0.7344\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8264 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8281 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4001 - accuracy: 0.8264 - val_loss: 0.5396 - val_accuracy: 0.7344\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8264 - val_loss: 0.5396 - val_accuracy: 0.7344\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8264 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3999 - accuracy: 0.8281 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8264 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3999 - accuracy: 0.8281 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8281 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8281 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8281 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8281 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8281 - val_loss: 0.5399 - val_accuracy: 0.7292\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3998 - accuracy: 0.8281 - val_loss: 0.5399 - val_accuracy: 0.7292\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.8264 - val_loss: 0.5400 - val_accuracy: 0.7344\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3996 - accuracy: 0.8281 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.8281 - val_loss: 0.5400 - val_accuracy: 0.7344\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.8281 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8281 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.8281 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8281 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.8264 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.8281 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3996 - accuracy: 0.8281 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8264 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3996 - accuracy: 0.8281 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8281 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8281 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8281 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8281 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8281 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3994 - accuracy: 0.8264 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8264 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3995 - accuracy: 0.8264 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3992 - accuracy: 0.8281 - val_loss: 0.5406 - val_accuracy: 0.7344\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3993 - accuracy: 0.8281 - val_loss: 0.5406 - val_accuracy: 0.7344\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8281 - val_loss: 0.5406 - val_accuracy: 0.7344\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8281 - val_loss: 0.5406 - val_accuracy: 0.7344\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3993 - accuracy: 0.8264 - val_loss: 0.5407 - val_accuracy: 0.7344\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3992 - accuracy: 0.8264 - val_loss: 0.5407 - val_accuracy: 0.7344\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3992 - accuracy: 0.8264 - val_loss: 0.5407 - val_accuracy: 0.7344\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8264 - val_loss: 0.5408 - val_accuracy: 0.7292\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8264 - val_loss: 0.5408 - val_accuracy: 0.7292\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3992 - accuracy: 0.8281 - val_loss: 0.5408 - val_accuracy: 0.7292\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8281 - val_loss: 0.5408 - val_accuracy: 0.7292\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8299 - val_loss: 0.5409 - val_accuracy: 0.7292\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8281 - val_loss: 0.5409 - val_accuracy: 0.7292\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3992 - accuracy: 0.8264 - val_loss: 0.5409 - val_accuracy: 0.7292\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3990 - accuracy: 0.8281 - val_loss: 0.5408 - val_accuracy: 0.7292\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3991 - accuracy: 0.8264 - val_loss: 0.5408 - val_accuracy: 0.7292\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3990 - accuracy: 0.8264 - val_loss: 0.5407 - val_accuracy: 0.7292\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3990 - accuracy: 0.8281 - val_loss: 0.5407 - val_accuracy: 0.7292\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3990 - accuracy: 0.8281 - val_loss: 0.5406 - val_accuracy: 0.7292\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3989 - accuracy: 0.8281 - val_loss: 0.5407 - val_accuracy: 0.7344\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3989 - accuracy: 0.8264 - val_loss: 0.5407 - val_accuracy: 0.7344\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3988 - accuracy: 0.8264 - val_loss: 0.5407 - val_accuracy: 0.7344\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3988 - accuracy: 0.8264 - val_loss: 0.5406 - val_accuracy: 0.7344\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3989 - accuracy: 0.8299 - val_loss: 0.5406 - val_accuracy: 0.7344\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.8281 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8281 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3988 - accuracy: 0.8264 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8264 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.8264 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.8264 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.8264 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8281 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8281 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8281 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8264 - val_loss: 0.5404 - val_accuracy: 0.7292\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8264 - val_loss: 0.5403 - val_accuracy: 0.7292\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8281 - val_loss: 0.5403 - val_accuracy: 0.7292\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8264 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.8281 - val_loss: 0.5402 - val_accuracy: 0.7292\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8299 - val_loss: 0.5403 - val_accuracy: 0.7292\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3983 - accuracy: 0.8264 - val_loss: 0.5403 - val_accuracy: 0.7292\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3984 - accuracy: 0.8299 - val_loss: 0.5403 - val_accuracy: 0.7292\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3982 - accuracy: 0.8247 - val_loss: 0.5402 - val_accuracy: 0.7292\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.8281 - val_loss: 0.5402 - val_accuracy: 0.7292\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3982 - accuracy: 0.8264 - val_loss: 0.5402 - val_accuracy: 0.7292\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3982 - accuracy: 0.8281 - val_loss: 0.5402 - val_accuracy: 0.7292\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3983 - accuracy: 0.8281 - val_loss: 0.5402 - val_accuracy: 0.7292\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8247 - val_loss: 0.5402 - val_accuracy: 0.7292\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3981 - accuracy: 0.8281 - val_loss: 0.5402 - val_accuracy: 0.7292\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8264 - val_loss: 0.5402 - val_accuracy: 0.7292\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8264 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8264 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.8264 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.8247 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.8264 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3979 - accuracy: 0.8264 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8264 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.8229 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3978 - accuracy: 0.8247 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8264 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3978 - accuracy: 0.8316 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8264 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3979 - accuracy: 0.8229 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3976 - accuracy: 0.8247 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3977 - accuracy: 0.8247 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8281 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.8281 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8264 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.8264 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.8247 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.8264 - val_loss: 0.5400 - val_accuracy: 0.7292\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3974 - accuracy: 0.8247 - val_loss: 0.5400 - val_accuracy: 0.7292\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x24110afe740>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O número ideal de épocas para essa base de dados seria algo entorno de 100 e 200 épocas, pois o gráfico acima indica que pouco depois desse número de épocas o erro de validação começa a subir podendo levar ao overfitting. Sendo assim, algo em torno de 100 e 200 épocas nos daria um modelo bem ajustado com boa generalização."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Now it's your turn.  Do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model\n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "# \n",
    "model_new = Sequential([\n",
    "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(6, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28 (Dense)            (None, 6)                 54        \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 6)                 42        \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 1s 15ms/step - loss: 0.7872 - accuracy: 0.3976 - val_loss: 0.7641 - val_accuracy: 0.3958\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.7501 - accuracy: 0.4288 - val_loss: 0.7365 - val_accuracy: 0.4375\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7234 - accuracy: 0.4809 - val_loss: 0.7164 - val_accuracy: 0.5052\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7035 - accuracy: 0.5399 - val_loss: 0.7013 - val_accuracy: 0.5417\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6884 - accuracy: 0.5833 - val_loss: 0.6899 - val_accuracy: 0.5573\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6768 - accuracy: 0.5938 - val_loss: 0.6809 - val_accuracy: 0.5521\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6673 - accuracy: 0.6302 - val_loss: 0.6738 - val_accuracy: 0.6250\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6597 - accuracy: 0.6424 - val_loss: 0.6679 - val_accuracy: 0.6302\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6533 - accuracy: 0.6562 - val_loss: 0.6629 - val_accuracy: 0.6406\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6477 - accuracy: 0.6615 - val_loss: 0.6585 - val_accuracy: 0.6458\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6430 - accuracy: 0.6615 - val_loss: 0.6547 - val_accuracy: 0.6615\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6387 - accuracy: 0.6788 - val_loss: 0.6512 - val_accuracy: 0.6771\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6349 - accuracy: 0.6858 - val_loss: 0.6480 - val_accuracy: 0.6771\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6314 - accuracy: 0.6892 - val_loss: 0.6451 - val_accuracy: 0.6823\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6280 - accuracy: 0.6944 - val_loss: 0.6422 - val_accuracy: 0.6771\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6249 - accuracy: 0.6979 - val_loss: 0.6394 - val_accuracy: 0.6667\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6218 - accuracy: 0.6979 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6190 - accuracy: 0.6979 - val_loss: 0.6340 - val_accuracy: 0.6719\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6160 - accuracy: 0.6997 - val_loss: 0.6313 - val_accuracy: 0.6719\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6132 - accuracy: 0.7066 - val_loss: 0.6288 - val_accuracy: 0.6719\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6105 - accuracy: 0.7083 - val_loss: 0.6261 - val_accuracy: 0.6771\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6078 - accuracy: 0.7118 - val_loss: 0.6235 - val_accuracy: 0.6771\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6050 - accuracy: 0.7101 - val_loss: 0.6209 - val_accuracy: 0.6771\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6023 - accuracy: 0.7118 - val_loss: 0.6182 - val_accuracy: 0.6823\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5996 - accuracy: 0.7101 - val_loss: 0.6155 - val_accuracy: 0.6875\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5969 - accuracy: 0.7101 - val_loss: 0.6128 - val_accuracy: 0.6927\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.7135 - val_loss: 0.6101 - val_accuracy: 0.7135\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5917 - accuracy: 0.7153 - val_loss: 0.6073 - val_accuracy: 0.7135\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5890 - accuracy: 0.7188 - val_loss: 0.6044 - val_accuracy: 0.7031\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5863 - accuracy: 0.7153 - val_loss: 0.6016 - val_accuracy: 0.7031\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5836 - accuracy: 0.7222 - val_loss: 0.5989 - val_accuracy: 0.6979\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5810 - accuracy: 0.7205 - val_loss: 0.5960 - val_accuracy: 0.6979\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5783 - accuracy: 0.7222 - val_loss: 0.5931 - val_accuracy: 0.6979\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5755 - accuracy: 0.7188 - val_loss: 0.5902 - val_accuracy: 0.7031\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5727 - accuracy: 0.7240 - val_loss: 0.5873 - val_accuracy: 0.7083\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5699 - accuracy: 0.7222 - val_loss: 0.5844 - val_accuracy: 0.7083\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5671 - accuracy: 0.7292 - val_loss: 0.5816 - val_accuracy: 0.7188\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5643 - accuracy: 0.7344 - val_loss: 0.5788 - val_accuracy: 0.7188\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5616 - accuracy: 0.7361 - val_loss: 0.5760 - val_accuracy: 0.7240\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.7361 - val_loss: 0.5732 - val_accuracy: 0.7292\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.7396 - val_loss: 0.5704 - val_accuracy: 0.7344\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5531 - accuracy: 0.7396 - val_loss: 0.5677 - val_accuracy: 0.7448\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5504 - accuracy: 0.7483 - val_loss: 0.5651 - val_accuracy: 0.7500\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5477 - accuracy: 0.7500 - val_loss: 0.5624 - val_accuracy: 0.7500\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5450 - accuracy: 0.7587 - val_loss: 0.5598 - val_accuracy: 0.7500\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7656 - val_loss: 0.5573 - val_accuracy: 0.7500\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5395 - accuracy: 0.7639 - val_loss: 0.5548 - val_accuracy: 0.7500\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.5367 - accuracy: 0.7656 - val_loss: 0.5523 - val_accuracy: 0.7656\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5342 - accuracy: 0.7656 - val_loss: 0.5499 - val_accuracy: 0.7656\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5317 - accuracy: 0.7639 - val_loss: 0.5475 - val_accuracy: 0.7656\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5293 - accuracy: 0.7656 - val_loss: 0.5452 - val_accuracy: 0.7656\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5270 - accuracy: 0.7656 - val_loss: 0.5429 - val_accuracy: 0.7708\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5248 - accuracy: 0.7622 - val_loss: 0.5408 - val_accuracy: 0.7708\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5226 - accuracy: 0.7622 - val_loss: 0.5386 - val_accuracy: 0.7708\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.7604 - val_loss: 0.5365 - val_accuracy: 0.7604\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7639 - val_loss: 0.5346 - val_accuracy: 0.7604\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5164 - accuracy: 0.7691 - val_loss: 0.5327 - val_accuracy: 0.7604\n",
      "Epoch 58/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5145 - accuracy: 0.7708 - val_loss: 0.5309 - val_accuracy: 0.7552\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7726 - val_loss: 0.5291 - val_accuracy: 0.7604\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7726 - val_loss: 0.5274 - val_accuracy: 0.7552\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5089 - accuracy: 0.7743 - val_loss: 0.5258 - val_accuracy: 0.7604\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7726 - val_loss: 0.5243 - val_accuracy: 0.7604\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5054 - accuracy: 0.7691 - val_loss: 0.5229 - val_accuracy: 0.7604\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7691 - val_loss: 0.5214 - val_accuracy: 0.7604\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.7691 - val_loss: 0.5199 - val_accuracy: 0.7552\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.7691 - val_loss: 0.5185 - val_accuracy: 0.7552\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4989 - accuracy: 0.7691 - val_loss: 0.5172 - val_accuracy: 0.7552\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4974 - accuracy: 0.7708 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7691 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7691 - val_loss: 0.5138 - val_accuracy: 0.7552\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.7726 - val_loss: 0.5128 - val_accuracy: 0.7604\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7708 - val_loss: 0.5118 - val_accuracy: 0.7604\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.7708 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.7726 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.7708 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.7726 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7743 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7760 - val_loss: 0.5075 - val_accuracy: 0.7656\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.7760 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7743 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.7760 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.7760 - val_loss: 0.5053 - val_accuracy: 0.7604\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.7760 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4810 - accuracy: 0.7760 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.7778 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7778 - val_loss: 0.5036 - val_accuracy: 0.7708\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7778 - val_loss: 0.5033 - val_accuracy: 0.7708\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7778 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7778 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7795 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7795 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7795 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7795 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7760 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4737 - accuracy: 0.7795 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7795 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.7778 - val_loss: 0.5006 - val_accuracy: 0.7656\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7812 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7812 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7847 - val_loss: 0.5000 - val_accuracy: 0.7708\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7847 - val_loss: 0.5000 - val_accuracy: 0.7708\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7847 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7865 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7847 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7847 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7760\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7830 - val_loss: 0.4992 - val_accuracy: 0.7760\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.7847 - val_loss: 0.4991 - val_accuracy: 0.7760\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7847 - val_loss: 0.4990 - val_accuracy: 0.7760\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7847 - val_loss: 0.4990 - val_accuracy: 0.7760\n",
      "Epoch 115/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4657 - accuracy: 0.7865 - val_loss: 0.4989 - val_accuracy: 0.7760\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.4988 - val_accuracy: 0.7760\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7847 - val_loss: 0.4987 - val_accuracy: 0.7760\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4647 - accuracy: 0.7847 - val_loss: 0.4986 - val_accuracy: 0.7760\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4644 - accuracy: 0.7847 - val_loss: 0.4986 - val_accuracy: 0.7760\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4641 - accuracy: 0.7847 - val_loss: 0.4985 - val_accuracy: 0.7760\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4637 - accuracy: 0.7847 - val_loss: 0.4984 - val_accuracy: 0.7760\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4634 - accuracy: 0.7830 - val_loss: 0.4984 - val_accuracy: 0.7760\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4631 - accuracy: 0.7847 - val_loss: 0.4983 - val_accuracy: 0.7760\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4628 - accuracy: 0.7847 - val_loss: 0.4983 - val_accuracy: 0.7760\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4625 - accuracy: 0.7847 - val_loss: 0.4983 - val_accuracy: 0.7760\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.7847 - val_loss: 0.4982 - val_accuracy: 0.7760\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7830 - val_loss: 0.4981 - val_accuracy: 0.7760\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7830 - val_loss: 0.4981 - val_accuracy: 0.7760\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7760\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7847 - val_loss: 0.4980 - val_accuracy: 0.7760\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7847 - val_loss: 0.4978 - val_accuracy: 0.7760\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7760\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7830 - val_loss: 0.4977 - val_accuracy: 0.7760\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4977 - val_accuracy: 0.7760\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7812 - val_loss: 0.4977 - val_accuracy: 0.7760\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4976 - val_accuracy: 0.7760\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7812 - val_loss: 0.4975 - val_accuracy: 0.7760\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4974 - val_accuracy: 0.7760\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4972 - val_accuracy: 0.7760\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7812 - val_loss: 0.4970 - val_accuracy: 0.7760\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4579 - accuracy: 0.7812 - val_loss: 0.4970 - val_accuracy: 0.7760\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4969 - val_accuracy: 0.7760\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4969 - val_accuracy: 0.7760\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7760 - val_loss: 0.4968 - val_accuracy: 0.7760\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4570 - accuracy: 0.7795 - val_loss: 0.4967 - val_accuracy: 0.7760\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7760\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7795 - val_loss: 0.4966 - val_accuracy: 0.7760\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7795 - val_loss: 0.4966 - val_accuracy: 0.7760\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7778 - val_loss: 0.4966 - val_accuracy: 0.7760\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7778 - val_loss: 0.4965 - val_accuracy: 0.7760\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7778 - val_loss: 0.4965 - val_accuracy: 0.7760\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7760\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7812 - val_loss: 0.4964 - val_accuracy: 0.7760\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4552 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7760\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4550 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7760\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7760\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7812 - val_loss: 0.4964 - val_accuracy: 0.7760\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7760\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7760\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7760\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7760\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.7778 - val_loss: 0.4963 - val_accuracy: 0.7760\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7778 - val_loss: 0.4962 - val_accuracy: 0.7760\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.7830 - val_loss: 0.4963 - val_accuracy: 0.7760\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7778 - val_loss: 0.4962 - val_accuracy: 0.7760\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7795 - val_loss: 0.4962 - val_accuracy: 0.7760\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7812 - val_loss: 0.4962 - val_accuracy: 0.7760\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.7795 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7778 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.7795 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7812 - val_loss: 0.4959 - val_accuracy: 0.7760\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7830 - val_loss: 0.4959 - val_accuracy: 0.7760\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4517 - accuracy: 0.7795 - val_loss: 0.4959 - val_accuracy: 0.7760\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7812 - val_loss: 0.4958 - val_accuracy: 0.7708\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7795 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7795 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7795 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7812 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7795 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7795 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7778 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7812 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7812 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7795 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7812 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7812 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7795 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7778 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7812 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4487 - accuracy: 0.7795 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4486 - accuracy: 0.7795 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7795 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7795 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7795 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7778 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7778 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7812 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7778 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7778 - val_loss: 0.4962 - val_accuracy: 0.7708\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7778 - val_loss: 0.4962 - val_accuracy: 0.7708\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7795 - val_loss: 0.4962 - val_accuracy: 0.7708\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7778 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7812 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7795 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7778 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7795 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4460 - accuracy: 0.7812 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4460 - accuracy: 0.7760 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4455 - accuracy: 0.7812 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7795 - val_loss: 0.4965 - val_accuracy: 0.7656\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7778 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7778 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7795 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.7778 - val_loss: 0.4967 - val_accuracy: 0.7604\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.7795 - val_loss: 0.4968 - val_accuracy: 0.7604\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.7778 - val_loss: 0.4968 - val_accuracy: 0.7604\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.7795 - val_loss: 0.4968 - val_accuracy: 0.7604\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7778 - val_loss: 0.4967 - val_accuracy: 0.7604\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7795 - val_loss: 0.4968 - val_accuracy: 0.7604\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4443 - accuracy: 0.7778 - val_loss: 0.4968 - val_accuracy: 0.7604\n",
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.7778 - val_loss: 0.4968 - val_accuracy: 0.7604\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.7795 - val_loss: 0.4969 - val_accuracy: 0.7604\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.7778 - val_loss: 0.4969 - val_accuracy: 0.7604\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7795 - val_loss: 0.4969 - val_accuracy: 0.7604\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7778 - val_loss: 0.4969 - val_accuracy: 0.7604\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.7778 - val_loss: 0.4970 - val_accuracy: 0.7604\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4433 - accuracy: 0.7760 - val_loss: 0.4970 - val_accuracy: 0.7604\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4432 - accuracy: 0.7778 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4431 - accuracy: 0.7795 - val_loss: 0.4972 - val_accuracy: 0.7604\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4430 - accuracy: 0.7778 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7795 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7778 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4427 - accuracy: 0.7760 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.7778 - val_loss: 0.4972 - val_accuracy: 0.7604\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4425 - accuracy: 0.7760 - val_loss: 0.4973 - val_accuracy: 0.7604\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4423 - accuracy: 0.7760 - val_loss: 0.4974 - val_accuracy: 0.7604\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4422 - accuracy: 0.7778 - val_loss: 0.4974 - val_accuracy: 0.7604\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4421 - accuracy: 0.7743 - val_loss: 0.4974 - val_accuracy: 0.7604\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4420 - accuracy: 0.7778 - val_loss: 0.4975 - val_accuracy: 0.7604\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4421 - accuracy: 0.7795 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4418 - accuracy: 0.7760 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7760 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7760 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7760 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7795 - val_loss: 0.4978 - val_accuracy: 0.7604\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.7778 - val_loss: 0.4978 - val_accuracy: 0.7604\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7760 - val_loss: 0.4978 - val_accuracy: 0.7604\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7760 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7778 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7778 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7778 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4405 - accuracy: 0.7778 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7778 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.7778 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4402 - accuracy: 0.7778 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4402 - accuracy: 0.7778 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4400 - accuracy: 0.7778 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4400 - accuracy: 0.7778 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4398 - accuracy: 0.7778 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4398 - accuracy: 0.7778 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4396 - accuracy: 0.7778 - val_loss: 0.4983 - val_accuracy: 0.7604\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4396 - accuracy: 0.7778 - val_loss: 0.4983 - val_accuracy: 0.7604\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.7778 - val_loss: 0.4985 - val_accuracy: 0.7604\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.7778 - val_loss: 0.4986 - val_accuracy: 0.7604\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4392 - accuracy: 0.7778 - val_loss: 0.4986 - val_accuracy: 0.7604\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4393 - accuracy: 0.7778 - val_loss: 0.4986 - val_accuracy: 0.7604\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.7760 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7795 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7760 - val_loss: 0.4989 - val_accuracy: 0.7604\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.7778 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.7778 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4389 - accuracy: 0.7760 - val_loss: 0.4990 - val_accuracy: 0.7552\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.7778 - val_loss: 0.4990 - val_accuracy: 0.7552\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7778 - val_loss: 0.4991 - val_accuracy: 0.7552\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7760 - val_loss: 0.4992 - val_accuracy: 0.7552\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7760 - val_loss: 0.4992 - val_accuracy: 0.7552\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4384 - accuracy: 0.7760 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.7778 - val_loss: 0.4994 - val_accuracy: 0.7552\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7778 - val_loss: 0.4995 - val_accuracy: 0.7552\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.7760 - val_loss: 0.4996 - val_accuracy: 0.7552\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4382 - accuracy: 0.7760 - val_loss: 0.4997 - val_accuracy: 0.7552\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7760 - val_loss: 0.4996 - val_accuracy: 0.7552\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7760 - val_loss: 0.4998 - val_accuracy: 0.7552\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4379 - accuracy: 0.7778 - val_loss: 0.4999 - val_accuracy: 0.7552\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7760 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4379 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7552\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4377 - accuracy: 0.7760 - val_loss: 0.5002 - val_accuracy: 0.7552\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7552\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7760 - val_loss: 0.5003 - val_accuracy: 0.7552\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7778 - val_loss: 0.5004 - val_accuracy: 0.7552\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7760 - val_loss: 0.5004 - val_accuracy: 0.7552\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4374 - accuracy: 0.7760 - val_loss: 0.5006 - val_accuracy: 0.7552\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7760 - val_loss: 0.5006 - val_accuracy: 0.7552\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7778 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4373 - accuracy: 0.7760 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7778 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7760 - val_loss: 0.5009 - val_accuracy: 0.7552\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7778 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7778 - val_loss: 0.5010 - val_accuracy: 0.7552\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7778 - val_loss: 0.5011 - val_accuracy: 0.7552\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7778 - val_loss: 0.5011 - val_accuracy: 0.7552\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7778 - val_loss: 0.5012 - val_accuracy: 0.7552\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7795 - val_loss: 0.5011 - val_accuracy: 0.7552\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7552\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7778 - val_loss: 0.5012 - val_accuracy: 0.7552\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7778 - val_loss: 0.5013 - val_accuracy: 0.7552\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7778 - val_loss: 0.5013 - val_accuracy: 0.7552\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7778 - val_loss: 0.5013 - val_accuracy: 0.7552\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7552\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4361 - accuracy: 0.7778 - val_loss: 0.5014 - val_accuracy: 0.7552\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4360 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7552\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.7778 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7552\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7760 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7795 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7760 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4354 - accuracy: 0.7778 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4354 - accuracy: 0.7778 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4353 - accuracy: 0.7743 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4352 - accuracy: 0.7778 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4350 - accuracy: 0.7778 - val_loss: 0.5019 - val_accuracy: 0.7500\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4349 - accuracy: 0.7778 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4347 - accuracy: 0.7743 - val_loss: 0.5020 - val_accuracy: 0.7500\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.7760 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7743 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7743 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7743 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7760 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7760 - val_loss: 0.5023 - val_accuracy: 0.7604\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7743 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7760 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7778 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7760 - val_loss: 0.5023 - val_accuracy: 0.7604\n",
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7778 - val_loss: 0.5025 - val_accuracy: 0.7604\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7778 - val_loss: 0.5025 - val_accuracy: 0.7604\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7760 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4339 - accuracy: 0.7760 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7760 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7760 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7760 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7795 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7726 - val_loss: 0.5026 - val_accuracy: 0.7552\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7778 - val_loss: 0.5026 - val_accuracy: 0.7552\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7778 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7760 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7743 - val_loss: 0.5028 - val_accuracy: 0.7552\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7760 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.7778 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7743 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7726 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7760 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7778 - val_loss: 0.5029 - val_accuracy: 0.7552\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4326 - accuracy: 0.7743 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7760 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7726 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7760 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7743 - val_loss: 0.5030 - val_accuracy: 0.7552\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7743 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7760 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7778 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7743 - val_loss: 0.5032 - val_accuracy: 0.7552\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7743 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7778 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7743 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7778 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7760 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4317 - accuracy: 0.7795 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7778 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7726 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7760 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7743 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7760 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7760 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7743 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7743 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4312 - accuracy: 0.7778 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7795 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7778 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7795 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4309 - accuracy: 0.7778 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4309 - accuracy: 0.7778 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4308 - accuracy: 0.7778 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4306 - accuracy: 0.7760 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4307 - accuracy: 0.7760 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4306 - accuracy: 0.7778 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4304 - accuracy: 0.7778 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4304 - accuracy: 0.7812 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.7795 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7778 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7795 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4302 - accuracy: 0.7795 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7795 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.7812 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.7812 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7795 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7795 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.7795 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7795 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7812 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7812 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7795 - val_loss: 0.5036 - val_accuracy: 0.7500\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.7795 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7812 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4294 - accuracy: 0.7865 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7795 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7795 - val_loss: 0.5038 - val_accuracy: 0.7500\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7795 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7795 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7812 - val_loss: 0.5039 - val_accuracy: 0.7500\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7812 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7812 - val_loss: 0.5041 - val_accuracy: 0.7500\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7830 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7795 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7812 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7795 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4284 - accuracy: 0.7795 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4284 - accuracy: 0.7795 - val_loss: 0.5040 - val_accuracy: 0.7500\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7812 - val_loss: 0.5042 - val_accuracy: 0.7500\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7847 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7830 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7830 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7812 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7847 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7812 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7830 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7812 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7795 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7847 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4279 - accuracy: 0.7812 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7847 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7795 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7830 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7830 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7812 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7812 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7847 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7865 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7847 - val_loss: 0.5047 - val_accuracy: 0.7500\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7812 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7830 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4271 - accuracy: 0.7812 - val_loss: 0.5045 - val_accuracy: 0.7500\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7830 - val_loss: 0.5046 - val_accuracy: 0.7500\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7830 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7812 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.7830 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7830 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7830 - val_loss: 0.5048 - val_accuracy: 0.7500\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7847 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7830 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7830 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7830 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7830 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.7865 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7882 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4263 - accuracy: 0.7830 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7847 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7847 - val_loss: 0.5049 - val_accuracy: 0.7500\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7847 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7865 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7830 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.7847 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7865 - val_loss: 0.5051 - val_accuracy: 0.7500\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7882 - val_loss: 0.5050 - val_accuracy: 0.7500\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.7899 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4255 - accuracy: 0.7830 - val_loss: 0.5053 - val_accuracy: 0.7500\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7847 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7847 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7882 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7882 - val_loss: 0.5053 - val_accuracy: 0.7500\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7830 - val_loss: 0.5053 - val_accuracy: 0.7500\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7899 - val_loss: 0.5052 - val_accuracy: 0.7500\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7865 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7882 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7865 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7882 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7917 - val_loss: 0.5056 - val_accuracy: 0.7500\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.5057 - val_accuracy: 0.7500\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.7865 - val_loss: 0.5058 - val_accuracy: 0.7500\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.7882 - val_loss: 0.5058 - val_accuracy: 0.7500\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7882 - val_loss: 0.5058 - val_accuracy: 0.7500\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.5058 - val_accuracy: 0.7500\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7917 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7882 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7917 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.7882 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.7899 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7882 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4237 - accuracy: 0.7934 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.7917 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.7951 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.7917 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7899 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.7917 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.7899 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.7917 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4233 - accuracy: 0.7865 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.7899 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7899 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.7899 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7899 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7917 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7917 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.7917 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.7899 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7899 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.7847 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4229 - accuracy: 0.7934 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7917 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7899 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7917 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.7882 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7899 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.7934 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7899 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7917 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7899 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7934 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4228 - accuracy: 0.7917 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7882 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7934 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4224 - accuracy: 0.7917 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.7934 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.7917 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7934 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7934 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.7934 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7899 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4221 - accuracy: 0.7934 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.7934 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7934 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.7917 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.7917 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7917 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7934 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7951 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.7917 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7934 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4214 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7917 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7917 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.7899 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.7969 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7934 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.7934 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7934 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7934 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4208 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7917 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7934 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.7951 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7951 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7951 - val_loss: 0.5066 - val_accuracy: 0.7500\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.5069 - val_accuracy: 0.7552\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.7969 - val_loss: 0.5070 - val_accuracy: 0.7552\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.5070 - val_accuracy: 0.7552\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7969 - val_loss: 0.5070 - val_accuracy: 0.7552\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7951 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7951 - val_loss: 0.5069 - val_accuracy: 0.7552\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7951 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7969 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.7951 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7951 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7934 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4197 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.7986 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7951 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7951 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7951 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7951 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7934 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.7986 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.5076 - val_accuracy: 0.7552\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.7951 - val_loss: 0.5076 - val_accuracy: 0.7552\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7969 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8003 - val_loss: 0.5076 - val_accuracy: 0.7552\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.5076 - val_accuracy: 0.7552\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.7934 - val_loss: 0.5076 - val_accuracy: 0.7552\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7969 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.7934 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.7951 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7934 - val_loss: 0.5081 - val_accuracy: 0.7552\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.7969 - val_loss: 0.5083 - val_accuracy: 0.7552\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.7934 - val_loss: 0.5084 - val_accuracy: 0.7552\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.5086 - val_accuracy: 0.7552\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8003 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.7986 - val_loss: 0.5083 - val_accuracy: 0.7552\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7969 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.5086 - val_accuracy: 0.7552\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.8003 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7951 - val_loss: 0.5087 - val_accuracy: 0.7552\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4184 - accuracy: 0.7986 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7986 - val_loss: 0.5087 - val_accuracy: 0.7552\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.8021 - val_loss: 0.5087 - val_accuracy: 0.7552\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.7986 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7951 - val_loss: 0.5090 - val_accuracy: 0.7552\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.5091 - val_accuracy: 0.7552\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4176 - accuracy: 0.7986 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.7969 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.7986 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.7986 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8003 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.7969 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.7951 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.7986 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.7969 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.7951 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.7969 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.7986 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.8038 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8003 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.7986 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.7986 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.8003 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4172 - accuracy: 0.7986 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4174 - accuracy: 0.7969 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4171 - accuracy: 0.7986 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4171 - accuracy: 0.7986 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.7969 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4170 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4171 - accuracy: 0.7969 - val_loss: 0.5109 - val_accuracy: 0.7500\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4171 - accuracy: 0.7986 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4170 - accuracy: 0.8021 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.8021 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7604\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.7969 - val_loss: 0.5108 - val_accuracy: 0.7604\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4171 - accuracy: 0.7986 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.7969 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4170 - accuracy: 0.7986 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.8003 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7986 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.8021 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8003 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7500\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4169 - accuracy: 0.8003 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.7986 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.8038 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.7951 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.8003 - val_loss: 0.5118 - val_accuracy: 0.7500\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5118 - val_accuracy: 0.7500\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.7986 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.8003 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.7969 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.7986 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4164 - accuracy: 0.7986 - val_loss: 0.5121 - val_accuracy: 0.7500\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.7986 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.7986 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8003 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.7986 - val_loss: 0.5122 - val_accuracy: 0.7500\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.7986 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.7969 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8003 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.7986 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8021 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8003 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.8003 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.8003 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8003 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.7986 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8003 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.7986 - val_loss: 0.5127 - val_accuracy: 0.7604\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.8003 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.8003 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4155 - accuracy: 0.7986 - val_loss: 0.5132 - val_accuracy: 0.7604\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.8021 - val_loss: 0.5131 - val_accuracy: 0.7604\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.8021 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.7986 - val_loss: 0.5130 - val_accuracy: 0.7604\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5132 - val_accuracy: 0.7604\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.7986 - val_loss: 0.5133 - val_accuracy: 0.7604\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.8003 - val_loss: 0.5133 - val_accuracy: 0.7604\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.8003 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4154 - accuracy: 0.8003 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4154 - accuracy: 0.7986 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.8003 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8003 - val_loss: 0.5133 - val_accuracy: 0.7604\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.8003 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.8003 - val_loss: 0.5135 - val_accuracy: 0.7604\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8003 - val_loss: 0.5136 - val_accuracy: 0.7604\n",
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4153 - accuracy: 0.8003 - val_loss: 0.5136 - val_accuracy: 0.7604\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4152 - accuracy: 0.8003 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4152 - accuracy: 0.7986 - val_loss: 0.5139 - val_accuracy: 0.7604\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.8038 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.8003 - val_loss: 0.5141 - val_accuracy: 0.7656\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.8003 - val_loss: 0.5142 - val_accuracy: 0.7656\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.8021 - val_loss: 0.5139 - val_accuracy: 0.7604\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8003 - val_loss: 0.5139 - val_accuracy: 0.7604\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8021 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4150 - accuracy: 0.7986 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8021 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.7986 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.8003 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.7986 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8003 - val_loss: 0.5144 - val_accuracy: 0.7656\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.7986 - val_loss: 0.5144 - val_accuracy: 0.7656\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.8021 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.8003 - val_loss: 0.5146 - val_accuracy: 0.7656\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.8003 - val_loss: 0.5146 - val_accuracy: 0.7656\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4147 - accuracy: 0.8021 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4144 - accuracy: 0.8021 - val_loss: 0.5146 - val_accuracy: 0.7656\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4145 - accuracy: 0.8021 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4151 - accuracy: 0.8003 - val_loss: 0.5146 - val_accuracy: 0.7656\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4147 - accuracy: 0.8021 - val_loss: 0.5147 - val_accuracy: 0.7708\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4143 - accuracy: 0.8021 - val_loss: 0.5146 - val_accuracy: 0.7656\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.8003 - val_loss: 0.5146 - val_accuracy: 0.7656\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4146 - accuracy: 0.8038 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4142 - accuracy: 0.8003 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4143 - accuracy: 0.7986 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.7986 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.8038 - val_loss: 0.5150 - val_accuracy: 0.7656\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8021 - val_loss: 0.5148 - val_accuracy: 0.7708\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8021 - val_loss: 0.5150 - val_accuracy: 0.7708\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8021 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.7951 - val_loss: 0.5152 - val_accuracy: 0.7708\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.8021 - val_loss: 0.5149 - val_accuracy: 0.7708\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4142 - accuracy: 0.8021 - val_loss: 0.5149 - val_accuracy: 0.7708\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.8003 - val_loss: 0.5151 - val_accuracy: 0.7708\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4142 - accuracy: 0.8021 - val_loss: 0.5152 - val_accuracy: 0.7708\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8021 - val_loss: 0.5152 - val_accuracy: 0.7708\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8021 - val_loss: 0.5152 - val_accuracy: 0.7708\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8038 - val_loss: 0.5151 - val_accuracy: 0.7708\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8056 - val_loss: 0.5150 - val_accuracy: 0.7708\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8021 - val_loss: 0.5153 - val_accuracy: 0.7656\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8003 - val_loss: 0.5153 - val_accuracy: 0.7708\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4141 - accuracy: 0.8021 - val_loss: 0.5154 - val_accuracy: 0.7760\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8038 - val_loss: 0.5153 - val_accuracy: 0.7708\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8038 - val_loss: 0.5155 - val_accuracy: 0.7760\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8003 - val_loss: 0.5155 - val_accuracy: 0.7760\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4137 - accuracy: 0.8038 - val_loss: 0.5154 - val_accuracy: 0.7760\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.8038 - val_loss: 0.5154 - val_accuracy: 0.7708\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.7986 - val_loss: 0.5154 - val_accuracy: 0.7708\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4137 - accuracy: 0.8038 - val_loss: 0.5153 - val_accuracy: 0.7708\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.8038 - val_loss: 0.5154 - val_accuracy: 0.7708\n",
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.8003 - val_loss: 0.5155 - val_accuracy: 0.7760\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.8021 - val_loss: 0.5158 - val_accuracy: 0.7760\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4137 - accuracy: 0.8038 - val_loss: 0.5158 - val_accuracy: 0.7760\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4137 - accuracy: 0.8056 - val_loss: 0.5155 - val_accuracy: 0.7760\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4134 - accuracy: 0.8003 - val_loss: 0.5157 - val_accuracy: 0.7760\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7760\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.8056 - val_loss: 0.5156 - val_accuracy: 0.7760\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4136 - accuracy: 0.8003 - val_loss: 0.5154 - val_accuracy: 0.7760\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4137 - accuracy: 0.8038 - val_loss: 0.5156 - val_accuracy: 0.7760\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4136 - accuracy: 0.8003 - val_loss: 0.5158 - val_accuracy: 0.7760\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4135 - accuracy: 0.8021 - val_loss: 0.5156 - val_accuracy: 0.7760\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4135 - accuracy: 0.8021 - val_loss: 0.5158 - val_accuracy: 0.7760\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4136 - accuracy: 0.8056 - val_loss: 0.5159 - val_accuracy: 0.7760\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4136 - accuracy: 0.8056 - val_loss: 0.5160 - val_accuracy: 0.7760\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8021 - val_loss: 0.5158 - val_accuracy: 0.7760\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4134 - accuracy: 0.8038 - val_loss: 0.5159 - val_accuracy: 0.7760\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8038 - val_loss: 0.5159 - val_accuracy: 0.7760\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.8021 - val_loss: 0.5162 - val_accuracy: 0.7760\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.8090 - val_loss: 0.5161 - val_accuracy: 0.7760\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8056 - val_loss: 0.5162 - val_accuracy: 0.7760\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8073 - val_loss: 0.5162 - val_accuracy: 0.7760\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8056 - val_loss: 0.5162 - val_accuracy: 0.7760\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8038 - val_loss: 0.5162 - val_accuracy: 0.7760\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8003 - val_loss: 0.5163 - val_accuracy: 0.7760\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8021 - val_loss: 0.5162 - val_accuracy: 0.7760\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4131 - accuracy: 0.8090 - val_loss: 0.5163 - val_accuracy: 0.7760\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.7986 - val_loss: 0.5165 - val_accuracy: 0.7760\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8056 - val_loss: 0.5164 - val_accuracy: 0.7760\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8056 - val_loss: 0.5165 - val_accuracy: 0.7760\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8021 - val_loss: 0.5165 - val_accuracy: 0.7760\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.8038 - val_loss: 0.5165 - val_accuracy: 0.7760\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8056 - val_loss: 0.5165 - val_accuracy: 0.7760\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8056 - val_loss: 0.5165 - val_accuracy: 0.7760\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8073 - val_loss: 0.5164 - val_accuracy: 0.7760\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.8073 - val_loss: 0.5164 - val_accuracy: 0.7760\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.8073 - val_loss: 0.5164 - val_accuracy: 0.7760\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4131 - accuracy: 0.8003 - val_loss: 0.5168 - val_accuracy: 0.7760\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8021 - val_loss: 0.5167 - val_accuracy: 0.7760\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8056 - val_loss: 0.5169 - val_accuracy: 0.7760\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8056 - val_loss: 0.5167 - val_accuracy: 0.7760\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8003 - val_loss: 0.5167 - val_accuracy: 0.7760\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8003 - val_loss: 0.5168 - val_accuracy: 0.7760\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8021 - val_loss: 0.5168 - val_accuracy: 0.7760\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8073 - val_loss: 0.5165 - val_accuracy: 0.7760\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4130 - accuracy: 0.8021 - val_loss: 0.5164 - val_accuracy: 0.7760\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8056 - val_loss: 0.5165 - val_accuracy: 0.7760\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8056 - val_loss: 0.5164 - val_accuracy: 0.7760\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8021 - val_loss: 0.5167 - val_accuracy: 0.7760\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4128 - accuracy: 0.8021 - val_loss: 0.5166 - val_accuracy: 0.7760\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.7986 - val_loss: 0.5170 - val_accuracy: 0.7760\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.7986 - val_loss: 0.5172 - val_accuracy: 0.7760\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8056 - val_loss: 0.5171 - val_accuracy: 0.7760\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8056 - val_loss: 0.5168 - val_accuracy: 0.7760\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.8003 - val_loss: 0.5171 - val_accuracy: 0.7760\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8056 - val_loss: 0.5172 - val_accuracy: 0.7760\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8038 - val_loss: 0.5169 - val_accuracy: 0.7760\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7760\n",
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4127 - accuracy: 0.8003 - val_loss: 0.5173 - val_accuracy: 0.7760\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.8073 - val_loss: 0.5173 - val_accuracy: 0.7760\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.8038 - val_loss: 0.5174 - val_accuracy: 0.7760\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4128 - accuracy: 0.8038 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.8038 - val_loss: 0.5179 - val_accuracy: 0.7760\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4127 - accuracy: 0.8021 - val_loss: 0.5178 - val_accuracy: 0.7760\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.8003 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8038 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.8073 - val_loss: 0.5175 - val_accuracy: 0.7760\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.8021 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4126 - accuracy: 0.8056 - val_loss: 0.5178 - val_accuracy: 0.7760\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8073 - val_loss: 0.5176 - val_accuracy: 0.7760\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.8021 - val_loss: 0.5176 - val_accuracy: 0.7760\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.8056 - val_loss: 0.5178 - val_accuracy: 0.7760\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.8021 - val_loss: 0.5178 - val_accuracy: 0.7760\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8021 - val_loss: 0.5179 - val_accuracy: 0.7760\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8038 - val_loss: 0.5178 - val_accuracy: 0.7760\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8003 - val_loss: 0.5178 - val_accuracy: 0.7760\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.7986 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8003 - val_loss: 0.5178 - val_accuracy: 0.7760\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8021 - val_loss: 0.5179 - val_accuracy: 0.7760\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8038 - val_loss: 0.5180 - val_accuracy: 0.7760\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8056 - val_loss: 0.5179 - val_accuracy: 0.7760\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8038 - val_loss: 0.5180 - val_accuracy: 0.7760\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.8003 - val_loss: 0.5180 - val_accuracy: 0.7760\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4126 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7760\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4121 - accuracy: 0.8056 - val_loss: 0.5183 - val_accuracy: 0.7760\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8056 - val_loss: 0.5181 - val_accuracy: 0.7760\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4123 - accuracy: 0.8056 - val_loss: 0.5182 - val_accuracy: 0.7760\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8038 - val_loss: 0.5182 - val_accuracy: 0.7760\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8073 - val_loss: 0.5180 - val_accuracy: 0.7760\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8021 - val_loss: 0.5181 - val_accuracy: 0.7760\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8021 - val_loss: 0.5183 - val_accuracy: 0.7760\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8021 - val_loss: 0.5185 - val_accuracy: 0.7760\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8003 - val_loss: 0.5183 - val_accuracy: 0.7760\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.7986 - val_loss: 0.5186 - val_accuracy: 0.7760\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8056 - val_loss: 0.5184 - val_accuracy: 0.7760\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4121 - accuracy: 0.8038 - val_loss: 0.5184 - val_accuracy: 0.7760\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8003 - val_loss: 0.5185 - val_accuracy: 0.7760\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8021 - val_loss: 0.5186 - val_accuracy: 0.7760\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8003 - val_loss: 0.5186 - val_accuracy: 0.7760\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8038 - val_loss: 0.5187 - val_accuracy: 0.7760\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8038 - val_loss: 0.5187 - val_accuracy: 0.7760\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8021 - val_loss: 0.5187 - val_accuracy: 0.7760\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.7986 - val_loss: 0.5187 - val_accuracy: 0.7760\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8038 - val_loss: 0.5189 - val_accuracy: 0.7760\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8038 - val_loss: 0.5190 - val_accuracy: 0.7760\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8021 - val_loss: 0.5190 - val_accuracy: 0.7760\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8038 - val_loss: 0.5190 - val_accuracy: 0.7760\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8073 - val_loss: 0.5190 - val_accuracy: 0.7760\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8021 - val_loss: 0.5189 - val_accuracy: 0.7760\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8003 - val_loss: 0.5191 - val_accuracy: 0.7760\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8038 - val_loss: 0.5193 - val_accuracy: 0.7760\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8003 - val_loss: 0.5188 - val_accuracy: 0.7760\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8003 - val_loss: 0.5187 - val_accuracy: 0.7760\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8038 - val_loss: 0.5186 - val_accuracy: 0.7760\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.7986 - val_loss: 0.5189 - val_accuracy: 0.7760\n",
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8021 - val_loss: 0.5191 - val_accuracy: 0.7760\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8038 - val_loss: 0.5190 - val_accuracy: 0.7760\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8038 - val_loss: 0.5191 - val_accuracy: 0.7760\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8003 - val_loss: 0.5192 - val_accuracy: 0.7760\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.8021 - val_loss: 0.5193 - val_accuracy: 0.7760\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8003 - val_loss: 0.5195 - val_accuracy: 0.7760\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8056 - val_loss: 0.5193 - val_accuracy: 0.7760\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8021 - val_loss: 0.5193 - val_accuracy: 0.7760\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8038 - val_loss: 0.5195 - val_accuracy: 0.7760\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8003 - val_loss: 0.5193 - val_accuracy: 0.7760\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8056 - val_loss: 0.5194 - val_accuracy: 0.7760\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.7986 - val_loss: 0.5193 - val_accuracy: 0.7760\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8021 - val_loss: 0.5193 - val_accuracy: 0.7760\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.7986 - val_loss: 0.5194 - val_accuracy: 0.7760\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4117 - accuracy: 0.8003 - val_loss: 0.5192 - val_accuracy: 0.7760\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.8056 - val_loss: 0.5197 - val_accuracy: 0.7760\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8090 - val_loss: 0.5196 - val_accuracy: 0.7760\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4116 - accuracy: 0.8003 - val_loss: 0.5194 - val_accuracy: 0.7760\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.8056 - val_loss: 0.5197 - val_accuracy: 0.7760\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.8038 - val_loss: 0.5196 - val_accuracy: 0.7760\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.8038 - val_loss: 0.5197 - val_accuracy: 0.7760\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8056 - val_loss: 0.5197 - val_accuracy: 0.7760\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.8021 - val_loss: 0.5199 - val_accuracy: 0.7760\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8056 - val_loss: 0.5198 - val_accuracy: 0.7760\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.8038 - val_loss: 0.5197 - val_accuracy: 0.7760\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4118 - accuracy: 0.7986 - val_loss: 0.5199 - val_accuracy: 0.7760\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8056 - val_loss: 0.5200 - val_accuracy: 0.7760\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8038 - val_loss: 0.5201 - val_accuracy: 0.7760\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8038 - val_loss: 0.5200 - val_accuracy: 0.7760\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.8021 - val_loss: 0.5199 - val_accuracy: 0.7760\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8003 - val_loss: 0.5200 - val_accuracy: 0.7760\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8003 - val_loss: 0.5202 - val_accuracy: 0.7760\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8003 - val_loss: 0.5202 - val_accuracy: 0.7760\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8021 - val_loss: 0.5203 - val_accuracy: 0.7760\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8038 - val_loss: 0.5201 - val_accuracy: 0.7760\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8021 - val_loss: 0.5202 - val_accuracy: 0.7760\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.8021 - val_loss: 0.5200 - val_accuracy: 0.7760\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8003 - val_loss: 0.5203 - val_accuracy: 0.7760\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8038 - val_loss: 0.5201 - val_accuracy: 0.7760\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8003 - val_loss: 0.5201 - val_accuracy: 0.7760\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8003 - val_loss: 0.5203 - val_accuracy: 0.7760\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8003 - val_loss: 0.5204 - val_accuracy: 0.7760\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8090 - val_loss: 0.5202 - val_accuracy: 0.7760\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.8003 - val_loss: 0.5205 - val_accuracy: 0.7760\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.7986 - val_loss: 0.5203 - val_accuracy: 0.7760\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.8021 - val_loss: 0.5201 - val_accuracy: 0.7760\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.7986 - val_loss: 0.5205 - val_accuracy: 0.7760\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8021 - val_loss: 0.5203 - val_accuracy: 0.7760\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.8021 - val_loss: 0.5204 - val_accuracy: 0.7760\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8038 - val_loss: 0.5202 - val_accuracy: 0.7760\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8003 - val_loss: 0.5204 - val_accuracy: 0.7760\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8021 - val_loss: 0.5204 - val_accuracy: 0.7760\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8038 - val_loss: 0.5202 - val_accuracy: 0.7760\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8038 - val_loss: 0.5204 - val_accuracy: 0.7760\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8021 - val_loss: 0.5203 - val_accuracy: 0.7760\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8021 - val_loss: 0.5205 - val_accuracy: 0.7760\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4108 - accuracy: 0.8038 - val_loss: 0.5205 - val_accuracy: 0.7760\n",
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.8021 - val_loss: 0.5205 - val_accuracy: 0.7760\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8056 - val_loss: 0.5205 - val_accuracy: 0.7760\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8038 - val_loss: 0.5205 - val_accuracy: 0.7760\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8056 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8021 - val_loss: 0.5205 - val_accuracy: 0.7760\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8056 - val_loss: 0.5204 - val_accuracy: 0.7760\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8021 - val_loss: 0.5204 - val_accuracy: 0.7760\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8038 - val_loss: 0.5205 - val_accuracy: 0.7760\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4109 - accuracy: 0.7986 - val_loss: 0.5204 - val_accuracy: 0.7760\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8038 - val_loss: 0.5205 - val_accuracy: 0.7760\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.7986 - val_loss: 0.5208 - val_accuracy: 0.7760\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8038 - val_loss: 0.5208 - val_accuracy: 0.7760\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8021 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.8038 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8038 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8021 - val_loss: 0.5208 - val_accuracy: 0.7760\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8038 - val_loss: 0.5208 - val_accuracy: 0.7760\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8038 - val_loss: 0.5209 - val_accuracy: 0.7760\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8038 - val_loss: 0.5212 - val_accuracy: 0.7760\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8003 - val_loss: 0.5210 - val_accuracy: 0.7760\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8038 - val_loss: 0.5209 - val_accuracy: 0.7760\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8021 - val_loss: 0.5209 - val_accuracy: 0.7760\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8003 - val_loss: 0.5210 - val_accuracy: 0.7760\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8038 - val_loss: 0.5210 - val_accuracy: 0.7760\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8056 - val_loss: 0.5209 - val_accuracy: 0.7760\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8056 - val_loss: 0.5208 - val_accuracy: 0.7760\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8021 - val_loss: 0.5209 - val_accuracy: 0.7760\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8056 - val_loss: 0.5208 - val_accuracy: 0.7760\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8003 - val_loss: 0.5210 - val_accuracy: 0.7760\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8038 - val_loss: 0.5210 - val_accuracy: 0.7760\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.7969 - val_loss: 0.5211 - val_accuracy: 0.7760\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8003 - val_loss: 0.5211 - val_accuracy: 0.7760\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8038 - val_loss: 0.5210 - val_accuracy: 0.7760\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8038 - val_loss: 0.5211 - val_accuracy: 0.7760\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8056 - val_loss: 0.5212 - val_accuracy: 0.7760\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8003 - val_loss: 0.5214 - val_accuracy: 0.7760\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8038 - val_loss: 0.5213 - val_accuracy: 0.7760\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.8021 - val_loss: 0.5214 - val_accuracy: 0.7760\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8003 - val_loss: 0.5213 - val_accuracy: 0.7760\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8021 - val_loss: 0.5211 - val_accuracy: 0.7760\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8038 - val_loss: 0.5212 - val_accuracy: 0.7760\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8021 - val_loss: 0.5213 - val_accuracy: 0.7760\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.7986 - val_loss: 0.5215 - val_accuracy: 0.7760\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8021 - val_loss: 0.5214 - val_accuracy: 0.7760\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8003 - val_loss: 0.5212 - val_accuracy: 0.7760\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.8021 - val_loss: 0.5213 - val_accuracy: 0.7760\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8021 - val_loss: 0.5217 - val_accuracy: 0.7760\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4106 - accuracy: 0.8021 - val_loss: 0.5215 - val_accuracy: 0.7760\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.8021 - val_loss: 0.5214 - val_accuracy: 0.7760\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8003 - val_loss: 0.5216 - val_accuracy: 0.7760\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8021 - val_loss: 0.5217 - val_accuracy: 0.7760\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8038 - val_loss: 0.5215 - val_accuracy: 0.7760\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.7986 - val_loss: 0.5214 - val_accuracy: 0.7760\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8038 - val_loss: 0.5214 - val_accuracy: 0.7760\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8021 - val_loss: 0.5215 - val_accuracy: 0.7760\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8021 - val_loss: 0.5213 - val_accuracy: 0.7760\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8056 - val_loss: 0.5215 - val_accuracy: 0.7760\n",
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4100 - accuracy: 0.8003 - val_loss: 0.5216 - val_accuracy: 0.7760\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8021 - val_loss: 0.5215 - val_accuracy: 0.7760\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8038 - val_loss: 0.5213 - val_accuracy: 0.7760\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.8056 - val_loss: 0.5216 - val_accuracy: 0.7760\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8073 - val_loss: 0.5215 - val_accuracy: 0.7760\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8090 - val_loss: 0.5216 - val_accuracy: 0.7760\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.8021 - val_loss: 0.5213 - val_accuracy: 0.7760\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8056 - val_loss: 0.5212 - val_accuracy: 0.7760\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8038 - val_loss: 0.5212 - val_accuracy: 0.7812\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8003 - val_loss: 0.5211 - val_accuracy: 0.7812\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4101 - accuracy: 0.8038 - val_loss: 0.5212 - val_accuracy: 0.7760\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8073 - val_loss: 0.5211 - val_accuracy: 0.7812\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8003 - val_loss: 0.5212 - val_accuracy: 0.7760\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8038 - val_loss: 0.5213 - val_accuracy: 0.7760\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8038 - val_loss: 0.5214 - val_accuracy: 0.7760\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8038 - val_loss: 0.5212 - val_accuracy: 0.7760\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.7986 - val_loss: 0.5209 - val_accuracy: 0.7760\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.8003 - val_loss: 0.5211 - val_accuracy: 0.7760\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8038 - val_loss: 0.5213 - val_accuracy: 0.7760\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8038 - val_loss: 0.5213 - val_accuracy: 0.7812\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8038 - val_loss: 0.5217 - val_accuracy: 0.7760\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.7986 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8056 - val_loss: 0.5218 - val_accuracy: 0.7760\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.7986 - val_loss: 0.5216 - val_accuracy: 0.7760\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8003 - val_loss: 0.5216 - val_accuracy: 0.7760\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8108 - val_loss: 0.5214 - val_accuracy: 0.7812\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8090 - val_loss: 0.5215 - val_accuracy: 0.7760\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8056 - val_loss: 0.5216 - val_accuracy: 0.7812\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8038 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8003 - val_loss: 0.5217 - val_accuracy: 0.7812\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8021 - val_loss: 0.5218 - val_accuracy: 0.7760\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8021 - val_loss: 0.5218 - val_accuracy: 0.7760\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8038 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4099 - accuracy: 0.8038 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.8003 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4100 - accuracy: 0.8021 - val_loss: 0.5222 - val_accuracy: 0.7760\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8038 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8038 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8021 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8073 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8073 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8021 - val_loss: 0.5219 - val_accuracy: 0.7760\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8021 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8038 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.8056 - val_loss: 0.5219 - val_accuracy: 0.7760\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8003 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.8038 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8056 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8038 - val_loss: 0.5222 - val_accuracy: 0.7760\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8038 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8038 - val_loss: 0.5222 - val_accuracy: 0.7760\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4095 - accuracy: 0.8038 - val_loss: 0.5221 - val_accuracy: 0.7812\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8056 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8038 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.7986 - val_loss: 0.5221 - val_accuracy: 0.7812\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.7986 - val_loss: 0.5224 - val_accuracy: 0.7812\n",
      "Epoch 1083/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8021 - val_loss: 0.5224 - val_accuracy: 0.7812\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8038 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8021 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4094 - accuracy: 0.7986 - val_loss: 0.5221 - val_accuracy: 0.7812\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8003 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8003 - val_loss: 0.5223 - val_accuracy: 0.7812\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8003 - val_loss: 0.5226 - val_accuracy: 0.7812\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8038 - val_loss: 0.5228 - val_accuracy: 0.7812\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8056 - val_loss: 0.5224 - val_accuracy: 0.7812\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8056 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8038 - val_loss: 0.5223 - val_accuracy: 0.7812\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4095 - accuracy: 0.8056 - val_loss: 0.5225 - val_accuracy: 0.7812\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4096 - accuracy: 0.8021 - val_loss: 0.5226 - val_accuracy: 0.7812\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8056 - val_loss: 0.5229 - val_accuracy: 0.7760\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8056 - val_loss: 0.5228 - val_accuracy: 0.7760\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8021 - val_loss: 0.5225 - val_accuracy: 0.7812\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8038 - val_loss: 0.5225 - val_accuracy: 0.7812\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8021 - val_loss: 0.5225 - val_accuracy: 0.7812\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8038 - val_loss: 0.5223 - val_accuracy: 0.7812\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8021 - val_loss: 0.5222 - val_accuracy: 0.7812\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8038 - val_loss: 0.5223 - val_accuracy: 0.7812\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4095 - accuracy: 0.8003 - val_loss: 0.5224 - val_accuracy: 0.7812\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8003 - val_loss: 0.5225 - val_accuracy: 0.7812\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8021 - val_loss: 0.5226 - val_accuracy: 0.7812\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8003 - val_loss: 0.5227 - val_accuracy: 0.7812\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8021 - val_loss: 0.5228 - val_accuracy: 0.7812\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8056 - val_loss: 0.5224 - val_accuracy: 0.7760\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8021 - val_loss: 0.5227 - val_accuracy: 0.7812\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8003 - val_loss: 0.5226 - val_accuracy: 0.7812\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.8056 - val_loss: 0.5226 - val_accuracy: 0.7812\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4095 - accuracy: 0.8038 - val_loss: 0.5225 - val_accuracy: 0.7812\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8003 - val_loss: 0.5226 - val_accuracy: 0.7812\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8021 - val_loss: 0.5227 - val_accuracy: 0.7812\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8021 - val_loss: 0.5230 - val_accuracy: 0.7812\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.8021 - val_loss: 0.5229 - val_accuracy: 0.7812\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8021 - val_loss: 0.5232 - val_accuracy: 0.7812\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8056 - val_loss: 0.5230 - val_accuracy: 0.7812\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8038 - val_loss: 0.5226 - val_accuracy: 0.7812\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4092 - accuracy: 0.8021 - val_loss: 0.5228 - val_accuracy: 0.7812\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8056 - val_loss: 0.5224 - val_accuracy: 0.7812\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8056 - val_loss: 0.5225 - val_accuracy: 0.7812\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8038 - val_loss: 0.5230 - val_accuracy: 0.7812\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8056 - val_loss: 0.5228 - val_accuracy: 0.7812\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.8038 - val_loss: 0.5227 - val_accuracy: 0.7812\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.7986 - val_loss: 0.5229 - val_accuracy: 0.7812\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8003 - val_loss: 0.5231 - val_accuracy: 0.7812\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8038 - val_loss: 0.5230 - val_accuracy: 0.7812\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4094 - accuracy: 0.8003 - val_loss: 0.5233 - val_accuracy: 0.7812\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8056 - val_loss: 0.5235 - val_accuracy: 0.7812\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8056 - val_loss: 0.5232 - val_accuracy: 0.7812\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8021 - val_loss: 0.5231 - val_accuracy: 0.7812\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8056 - val_loss: 0.5232 - val_accuracy: 0.7812\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8003 - val_loss: 0.5232 - val_accuracy: 0.7812\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4096 - accuracy: 0.8038 - val_loss: 0.5231 - val_accuracy: 0.7812\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8038 - val_loss: 0.5229 - val_accuracy: 0.7812\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8056 - val_loss: 0.5229 - val_accuracy: 0.7812\n",
      "Epoch 1139/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4088 - accuracy: 0.8038 - val_loss: 0.5224 - val_accuracy: 0.7812\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8021 - val_loss: 0.5225 - val_accuracy: 0.7812\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8038 - val_loss: 0.5226 - val_accuracy: 0.7812\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8038 - val_loss: 0.5225 - val_accuracy: 0.7812\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8021 - val_loss: 0.5226 - val_accuracy: 0.7812\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8056 - val_loss: 0.5223 - val_accuracy: 0.7812\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8056 - val_loss: 0.5222 - val_accuracy: 0.7812\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8021 - val_loss: 0.5222 - val_accuracy: 0.7812\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4089 - accuracy: 0.8038 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8038 - val_loss: 0.5222 - val_accuracy: 0.7812\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8021 - val_loss: 0.5222 - val_accuracy: 0.7812\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8038 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8021 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8021 - val_loss: 0.5221 - val_accuracy: 0.7812\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8056 - val_loss: 0.5223 - val_accuracy: 0.7812\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8038 - val_loss: 0.5221 - val_accuracy: 0.7812\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4087 - accuracy: 0.8003 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8021 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8003 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8021 - val_loss: 0.5221 - val_accuracy: 0.7812\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8021 - val_loss: 0.5221 - val_accuracy: 0.7812\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8038 - val_loss: 0.5224 - val_accuracy: 0.7812\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8056 - val_loss: 0.5222 - val_accuracy: 0.7812\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8038 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8038 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4086 - accuracy: 0.8021 - val_loss: 0.5217 - val_accuracy: 0.7812\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8021 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.7986 - val_loss: 0.5223 - val_accuracy: 0.7812\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8056 - val_loss: 0.5221 - val_accuracy: 0.7812\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.8003 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8003 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4085 - accuracy: 0.8056 - val_loss: 0.5222 - val_accuracy: 0.7812\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8021 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8021 - val_loss: 0.5223 - val_accuracy: 0.7812\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8056 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8021 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8038 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8038 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4080 - accuracy: 0.8038 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8003 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8021 - val_loss: 0.5217 - val_accuracy: 0.7812\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8003 - val_loss: 0.5221 - val_accuracy: 0.7812\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8056 - val_loss: 0.5217 - val_accuracy: 0.7812\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8021 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8038 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8038 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4078 - accuracy: 0.8021 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8038 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8021 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8038 - val_loss: 0.5217 - val_accuracy: 0.7812\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8003 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8021 - val_loss: 0.5216 - val_accuracy: 0.7812\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8038 - val_loss: 0.5217 - val_accuracy: 0.7812\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8038 - val_loss: 0.5217 - val_accuracy: 0.7812\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4078 - accuracy: 0.8056 - val_loss: 0.5217 - val_accuracy: 0.7812\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8038 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
      "Epoch 1195/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8056 - val_loss: 0.5214 - val_accuracy: 0.7812\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8021 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8038 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8021 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.8021 - val_loss: 0.5213 - val_accuracy: 0.7812\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4077 - accuracy: 0.8038 - val_loss: 0.5214 - val_accuracy: 0.7812\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8038 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8038 - val_loss: 0.5213 - val_accuracy: 0.7812\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8056 - val_loss: 0.5214 - val_accuracy: 0.7812\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8038 - val_loss: 0.5214 - val_accuracy: 0.7812\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8038 - val_loss: 0.5216 - val_accuracy: 0.7812\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8038 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4071 - accuracy: 0.8038 - val_loss: 0.5214 - val_accuracy: 0.7812\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8056 - val_loss: 0.5212 - val_accuracy: 0.7812\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8038 - val_loss: 0.5213 - val_accuracy: 0.7812\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8021 - val_loss: 0.5213 - val_accuracy: 0.7760\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8038 - val_loss: 0.5213 - val_accuracy: 0.7812\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8038 - val_loss: 0.5212 - val_accuracy: 0.7760\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8038 - val_loss: 0.5215 - val_accuracy: 0.7760\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8021 - val_loss: 0.5216 - val_accuracy: 0.7760\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.7951 - val_loss: 0.5217 - val_accuracy: 0.7812\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4071 - accuracy: 0.8003 - val_loss: 0.5215 - val_accuracy: 0.7760\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8056 - val_loss: 0.5215 - val_accuracy: 0.7760\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.7986 - val_loss: 0.5219 - val_accuracy: 0.7865\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8073 - val_loss: 0.5216 - val_accuracy: 0.7760\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8038 - val_loss: 0.5214 - val_accuracy: 0.7760\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8056 - val_loss: 0.5210 - val_accuracy: 0.7760\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8038 - val_loss: 0.5210 - val_accuracy: 0.7760\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8038 - val_loss: 0.5211 - val_accuracy: 0.7760\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4073 - accuracy: 0.8021 - val_loss: 0.5214 - val_accuracy: 0.7760\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8038 - val_loss: 0.5217 - val_accuracy: 0.7760\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8038 - val_loss: 0.5217 - val_accuracy: 0.7760\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8003 - val_loss: 0.5215 - val_accuracy: 0.7760\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8038 - val_loss: 0.5215 - val_accuracy: 0.7760\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8038 - val_loss: 0.5216 - val_accuracy: 0.7760\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8003 - val_loss: 0.5215 - val_accuracy: 0.7760\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8003 - val_loss: 0.5216 - val_accuracy: 0.7760\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4071 - accuracy: 0.8038 - val_loss: 0.5219 - val_accuracy: 0.7760\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8003 - val_loss: 0.5219 - val_accuracy: 0.7760\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8056 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.8038 - val_loss: 0.5219 - val_accuracy: 0.7760\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8073 - val_loss: 0.5222 - val_accuracy: 0.7760\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8003 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8003 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4069 - accuracy: 0.8021 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8021 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8021 - val_loss: 0.5219 - val_accuracy: 0.7760\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8038 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8021 - val_loss: 0.5221 - val_accuracy: 0.7760\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8038 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8038 - val_loss: 0.5218 - val_accuracy: 0.7760\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4066 - accuracy: 0.8003 - val_loss: 0.5219 - val_accuracy: 0.7760\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.7986 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8056 - val_loss: 0.5217 - val_accuracy: 0.7760\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8003 - val_loss: 0.5217 - val_accuracy: 0.7760\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8038 - val_loss: 0.5217 - val_accuracy: 0.7760\n",
      "Epoch 1251/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8056 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8003 - val_loss: 0.5221 - val_accuracy: 0.7812\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.8021 - val_loss: 0.5219 - val_accuracy: 0.7760\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4070 - accuracy: 0.8021 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8021 - val_loss: 0.5219 - val_accuracy: 0.7760\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8021 - val_loss: 0.5217 - val_accuracy: 0.7760\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8021 - val_loss: 0.5216 - val_accuracy: 0.7760\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8056 - val_loss: 0.5218 - val_accuracy: 0.7760\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8021 - val_loss: 0.5215 - val_accuracy: 0.7760\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8073 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8003 - val_loss: 0.5221 - val_accuracy: 0.7760\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4063 - accuracy: 0.8073 - val_loss: 0.5222 - val_accuracy: 0.7812\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8021 - val_loss: 0.5221 - val_accuracy: 0.7760\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8038 - val_loss: 0.5221 - val_accuracy: 0.7760\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8038 - val_loss: 0.5222 - val_accuracy: 0.7760\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.7986 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8038 - val_loss: 0.5218 - val_accuracy: 0.7760\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4067 - accuracy: 0.8003 - val_loss: 0.5222 - val_accuracy: 0.7760\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.7969 - val_loss: 0.5219 - val_accuracy: 0.7760\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8021 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4068 - accuracy: 0.8038 - val_loss: 0.5221 - val_accuracy: 0.7760\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.7986 - val_loss: 0.5219 - val_accuracy: 0.7760\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.7986 - val_loss: 0.5222 - val_accuracy: 0.7760\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8003 - val_loss: 0.5226 - val_accuracy: 0.7812\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8021 - val_loss: 0.5226 - val_accuracy: 0.7812\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4065 - accuracy: 0.8038 - val_loss: 0.5224 - val_accuracy: 0.7760\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8056 - val_loss: 0.5222 - val_accuracy: 0.7760\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8038 - val_loss: 0.5223 - val_accuracy: 0.7760\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8056 - val_loss: 0.5221 - val_accuracy: 0.7760\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8038 - val_loss: 0.5222 - val_accuracy: 0.7760\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8090 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8021 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8003 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4061 - accuracy: 0.8021 - val_loss: 0.5221 - val_accuracy: 0.7760\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.7986 - val_loss: 0.5224 - val_accuracy: 0.7812\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8003 - val_loss: 0.5224 - val_accuracy: 0.7812\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.7986 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8003 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8003 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8003 - val_loss: 0.5220 - val_accuracy: 0.7760\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8003 - val_loss: 0.5221 - val_accuracy: 0.7760\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4063 - accuracy: 0.8021 - val_loss: 0.5221 - val_accuracy: 0.7812\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8038 - val_loss: 0.5223 - val_accuracy: 0.7760\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8073 - val_loss: 0.5221 - val_accuracy: 0.7812\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8038 - val_loss: 0.5222 - val_accuracy: 0.7812\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8056 - val_loss: 0.5224 - val_accuracy: 0.7812\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8021 - val_loss: 0.5222 - val_accuracy: 0.7812\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.7969 - val_loss: 0.5221 - val_accuracy: 0.7812\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8003 - val_loss: 0.5222 - val_accuracy: 0.7812\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4062 - accuracy: 0.8021 - val_loss: 0.5223 - val_accuracy: 0.7865\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8038 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8038 - val_loss: 0.5221 - val_accuracy: 0.7812\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8056 - val_loss: 0.5221 - val_accuracy: 0.7865\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8038 - val_loss: 0.5224 - val_accuracy: 0.7865\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8021 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8073 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1307/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8038 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4059 - accuracy: 0.8021 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.7986 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8021 - val_loss: 0.5217 - val_accuracy: 0.7812\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8003 - val_loss: 0.5223 - val_accuracy: 0.7812\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.8038 - val_loss: 0.5225 - val_accuracy: 0.7865\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8038 - val_loss: 0.5221 - val_accuracy: 0.7812\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4057 - accuracy: 0.8056 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8021 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8021 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8021 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8021 - val_loss: 0.5222 - val_accuracy: 0.7812\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8003 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.7986 - val_loss: 0.5222 - val_accuracy: 0.7812\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8021 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4056 - accuracy: 0.8021 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8038 - val_loss: 0.5222 - val_accuracy: 0.7812\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8056 - val_loss: 0.5224 - val_accuracy: 0.7812\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4057 - accuracy: 0.8038 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.7986 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8038 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8021 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4057 - accuracy: 0.8021 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.8056 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8056 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8038 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8056 - val_loss: 0.5214 - val_accuracy: 0.7812\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4056 - accuracy: 0.8090 - val_loss: 0.5218 - val_accuracy: 0.7865\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4056 - accuracy: 0.8021 - val_loss: 0.5217 - val_accuracy: 0.7812\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8038 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8056 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4055 - accuracy: 0.8038 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4059 - accuracy: 0.8038 - val_loss: 0.5217 - val_accuracy: 0.7812\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4055 - accuracy: 0.8021 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4057 - accuracy: 0.7986 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4056 - accuracy: 0.8056 - val_loss: 0.5220 - val_accuracy: 0.7865\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4053 - accuracy: 0.8056 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4053 - accuracy: 0.8003 - val_loss: 0.5217 - val_accuracy: 0.7812\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4059 - accuracy: 0.8038 - val_loss: 0.5216 - val_accuracy: 0.7812\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4051 - accuracy: 0.8090 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4057 - accuracy: 0.7986 - val_loss: 0.5217 - val_accuracy: 0.7812\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4060 - accuracy: 0.8021 - val_loss: 0.5212 - val_accuracy: 0.7812\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4058 - accuracy: 0.8056 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8056 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.8056 - val_loss: 0.5214 - val_accuracy: 0.7812\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.8056 - val_loss: 0.5214 - val_accuracy: 0.7812\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4056 - accuracy: 0.8073 - val_loss: 0.5213 - val_accuracy: 0.7812\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8056 - val_loss: 0.5212 - val_accuracy: 0.7812\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4054 - accuracy: 0.8038 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4053 - accuracy: 0.8056 - val_loss: 0.5213 - val_accuracy: 0.7812\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4051 - accuracy: 0.8056 - val_loss: 0.5212 - val_accuracy: 0.7812\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4054 - accuracy: 0.8038 - val_loss: 0.5212 - val_accuracy: 0.7812\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8038 - val_loss: 0.5212 - val_accuracy: 0.7812\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.8056 - val_loss: 0.5212 - val_accuracy: 0.7812\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8056 - val_loss: 0.5212 - val_accuracy: 0.7812\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.8038 - val_loss: 0.5214 - val_accuracy: 0.7865\n",
      "Epoch 1363/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4051 - accuracy: 0.8021 - val_loss: 0.5212 - val_accuracy: 0.7812\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4054 - accuracy: 0.8056 - val_loss: 0.5211 - val_accuracy: 0.7812\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8056 - val_loss: 0.5210 - val_accuracy: 0.7812\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4056 - accuracy: 0.8038 - val_loss: 0.5210 - val_accuracy: 0.7812\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8021 - val_loss: 0.5212 - val_accuracy: 0.7812\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8056 - val_loss: 0.5212 - val_accuracy: 0.7812\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8073 - val_loss: 0.5211 - val_accuracy: 0.7812\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4051 - accuracy: 0.8038 - val_loss: 0.5210 - val_accuracy: 0.7812\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4050 - accuracy: 0.8021 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.8038 - val_loss: 0.5217 - val_accuracy: 0.7865\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.8038 - val_loss: 0.5213 - val_accuracy: 0.7812\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.8038 - val_loss: 0.5214 - val_accuracy: 0.7812\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8038 - val_loss: 0.5219 - val_accuracy: 0.7865\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4049 - accuracy: 0.8090 - val_loss: 0.5215 - val_accuracy: 0.7865\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8021 - val_loss: 0.5212 - val_accuracy: 0.7812\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8003 - val_loss: 0.5214 - val_accuracy: 0.7812\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8003 - val_loss: 0.5212 - val_accuracy: 0.7812\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8056 - val_loss: 0.5210 - val_accuracy: 0.7812\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8038 - val_loss: 0.5212 - val_accuracy: 0.7812\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4056 - accuracy: 0.8056 - val_loss: 0.5213 - val_accuracy: 0.7812\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4048 - accuracy: 0.8056 - val_loss: 0.5212 - val_accuracy: 0.7812\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.8038 - val_loss: 0.5211 - val_accuracy: 0.7812\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8021 - val_loss: 0.5210 - val_accuracy: 0.7812\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8021 - val_loss: 0.5214 - val_accuracy: 0.7812\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8090 - val_loss: 0.5213 - val_accuracy: 0.7812\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8056 - val_loss: 0.5210 - val_accuracy: 0.7812\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8021 - val_loss: 0.5211 - val_accuracy: 0.7812\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4051 - accuracy: 0.8090 - val_loss: 0.5209 - val_accuracy: 0.7812\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.8021 - val_loss: 0.5214 - val_accuracy: 0.7812\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8056 - val_loss: 0.5210 - val_accuracy: 0.7812\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.8038 - val_loss: 0.5210 - val_accuracy: 0.7812\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8021 - val_loss: 0.5211 - val_accuracy: 0.7812\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8090 - val_loss: 0.5210 - val_accuracy: 0.7812\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8038 - val_loss: 0.5209 - val_accuracy: 0.7812\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4053 - accuracy: 0.8038 - val_loss: 0.5210 - val_accuracy: 0.7812\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8021 - val_loss: 0.5210 - val_accuracy: 0.7812\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8038 - val_loss: 0.5209 - val_accuracy: 0.7812\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8021 - val_loss: 0.5211 - val_accuracy: 0.7812\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8021 - val_loss: 0.5210 - val_accuracy: 0.7812\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8038 - val_loss: 0.5209 - val_accuracy: 0.7812\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8021 - val_loss: 0.5211 - val_accuracy: 0.7812\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4047 - accuracy: 0.8073 - val_loss: 0.5213 - val_accuracy: 0.7865\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.8073 - val_loss: 0.5209 - val_accuracy: 0.7812\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8056 - val_loss: 0.5209 - val_accuracy: 0.7812\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.7986 - val_loss: 0.5210 - val_accuracy: 0.7865\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8038 - val_loss: 0.5207 - val_accuracy: 0.7812\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8038 - val_loss: 0.5206 - val_accuracy: 0.7812\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4047 - accuracy: 0.8021 - val_loss: 0.5207 - val_accuracy: 0.7812\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8038 - val_loss: 0.5212 - val_accuracy: 0.7865\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8038 - val_loss: 0.5211 - val_accuracy: 0.7865\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8056 - val_loss: 0.5209 - val_accuracy: 0.7865\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8021 - val_loss: 0.5208 - val_accuracy: 0.7865\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8056 - val_loss: 0.5209 - val_accuracy: 0.7865\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4046 - accuracy: 0.8056 - val_loss: 0.5206 - val_accuracy: 0.7812\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.8056 - val_loss: 0.5204 - val_accuracy: 0.7812\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8056 - val_loss: 0.5205 - val_accuracy: 0.7865\n",
      "Epoch 1419/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8073 - val_loss: 0.5204 - val_accuracy: 0.7865\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8021 - val_loss: 0.5202 - val_accuracy: 0.7812\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8056 - val_loss: 0.5200 - val_accuracy: 0.7812\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8038 - val_loss: 0.5200 - val_accuracy: 0.7812\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4046 - accuracy: 0.7986 - val_loss: 0.5203 - val_accuracy: 0.7865\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8021 - val_loss: 0.5203 - val_accuracy: 0.7865\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8038 - val_loss: 0.5202 - val_accuracy: 0.7865\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8003 - val_loss: 0.5202 - val_accuracy: 0.7865\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8038 - val_loss: 0.5201 - val_accuracy: 0.7865\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8073 - val_loss: 0.5198 - val_accuracy: 0.7812\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8021 - val_loss: 0.5197 - val_accuracy: 0.7812\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4050 - accuracy: 0.8073 - val_loss: 0.5198 - val_accuracy: 0.7812\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8003 - val_loss: 0.5201 - val_accuracy: 0.7865\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8090 - val_loss: 0.5199 - val_accuracy: 0.7812\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8056 - val_loss: 0.5200 - val_accuracy: 0.7865\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8056 - val_loss: 0.5202 - val_accuracy: 0.7865\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4044 - accuracy: 0.8038 - val_loss: 0.5200 - val_accuracy: 0.7865\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8056 - val_loss: 0.5200 - val_accuracy: 0.7865\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4042 - accuracy: 0.8056 - val_loss: 0.5199 - val_accuracy: 0.7865\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8073 - val_loss: 0.5199 - val_accuracy: 0.7865\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8038 - val_loss: 0.5197 - val_accuracy: 0.7865\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.7986 - val_loss: 0.5196 - val_accuracy: 0.7865\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8038 - val_loss: 0.5195 - val_accuracy: 0.7812\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8056 - val_loss: 0.5195 - val_accuracy: 0.7812\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8073 - val_loss: 0.5196 - val_accuracy: 0.7812\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4042 - accuracy: 0.8056 - val_loss: 0.5198 - val_accuracy: 0.7865\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8038 - val_loss: 0.5200 - val_accuracy: 0.7865\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8056 - val_loss: 0.5198 - val_accuracy: 0.7865\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.7969 - val_loss: 0.5202 - val_accuracy: 0.7865\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.8056 - val_loss: 0.5202 - val_accuracy: 0.7865\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4045 - accuracy: 0.8073 - val_loss: 0.5195 - val_accuracy: 0.7865\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4047 - accuracy: 0.8056 - val_loss: 0.5194 - val_accuracy: 0.7865\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4043 - accuracy: 0.8038 - val_loss: 0.5197 - val_accuracy: 0.7865\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8056 - val_loss: 0.5197 - val_accuracy: 0.7865\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4039 - accuracy: 0.8056 - val_loss: 0.5199 - val_accuracy: 0.7865\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4039 - accuracy: 0.8056 - val_loss: 0.5194 - val_accuracy: 0.7865\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8038 - val_loss: 0.5191 - val_accuracy: 0.7865\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8073 - val_loss: 0.5191 - val_accuracy: 0.7812\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4039 - accuracy: 0.8056 - val_loss: 0.5194 - val_accuracy: 0.7865\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8038 - val_loss: 0.5195 - val_accuracy: 0.7865\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8056 - val_loss: 0.5197 - val_accuracy: 0.7865\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8073 - val_loss: 0.5199 - val_accuracy: 0.7865\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8090 - val_loss: 0.5201 - val_accuracy: 0.7865\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4037 - accuracy: 0.8056 - val_loss: 0.5196 - val_accuracy: 0.7865\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8056 - val_loss: 0.5196 - val_accuracy: 0.7865\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4043 - accuracy: 0.8038 - val_loss: 0.5195 - val_accuracy: 0.7865\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8038 - val_loss: 0.5196 - val_accuracy: 0.7865\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8038 - val_loss: 0.5192 - val_accuracy: 0.7865\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8038 - val_loss: 0.5193 - val_accuracy: 0.7865\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.8038 - val_loss: 0.5190 - val_accuracy: 0.7812\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4044 - accuracy: 0.8073 - val_loss: 0.5189 - val_accuracy: 0.7812\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4040 - accuracy: 0.8090 - val_loss: 0.5192 - val_accuracy: 0.7865\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8073 - val_loss: 0.5192 - val_accuracy: 0.7865\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8056 - val_loss: 0.5190 - val_accuracy: 0.7865\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8038 - val_loss: 0.5190 - val_accuracy: 0.7812\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8073 - val_loss: 0.5190 - val_accuracy: 0.7812\n",
      "Epoch 1475/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8090 - val_loss: 0.5191 - val_accuracy: 0.7865\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4038 - accuracy: 0.8056 - val_loss: 0.5195 - val_accuracy: 0.7865\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8073 - val_loss: 0.5192 - val_accuracy: 0.7865\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8073 - val_loss: 0.5194 - val_accuracy: 0.7865\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8073 - val_loss: 0.5198 - val_accuracy: 0.7865\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8090 - val_loss: 0.5197 - val_accuracy: 0.7865\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8073 - val_loss: 0.5193 - val_accuracy: 0.7865\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4039 - accuracy: 0.8056 - val_loss: 0.5193 - val_accuracy: 0.7865\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4038 - accuracy: 0.8090 - val_loss: 0.5191 - val_accuracy: 0.7865\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8038 - val_loss: 0.5192 - val_accuracy: 0.7865\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8073 - val_loss: 0.5193 - val_accuracy: 0.7812\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8090 - val_loss: 0.5191 - val_accuracy: 0.7812\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8090 - val_loss: 0.5191 - val_accuracy: 0.7812\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8073 - val_loss: 0.5192 - val_accuracy: 0.7865\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4036 - accuracy: 0.8038 - val_loss: 0.5192 - val_accuracy: 0.7865\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8108 - val_loss: 0.5196 - val_accuracy: 0.7865\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8038 - val_loss: 0.5197 - val_accuracy: 0.7865\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8056 - val_loss: 0.5195 - val_accuracy: 0.7865\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8038 - val_loss: 0.5193 - val_accuracy: 0.7865\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8108 - val_loss: 0.5192 - val_accuracy: 0.7865\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8073 - val_loss: 0.5193 - val_accuracy: 0.7865\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4036 - accuracy: 0.8038 - val_loss: 0.5195 - val_accuracy: 0.7865\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8108 - val_loss: 0.5195 - val_accuracy: 0.7865\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8073 - val_loss: 0.5194 - val_accuracy: 0.7812\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4037 - accuracy: 0.8108 - val_loss: 0.5193 - val_accuracy: 0.7865\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8090 - val_loss: 0.5195 - val_accuracy: 0.7865\n"
     ]
    }
   ],
   "source": [
    "model_new.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_new = model_new.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1000us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_nn_new = model_new.predict(X_test_norm)\n",
    "y_pred_class_nn_new = (y_pred_prob_nn_new > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.786\n",
      "roc-auc is 0.817\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_new)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_new)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_new, 'NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x24113676110>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_new.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_new.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao rodar esse modelo podemos perceber que 1500 é um número elevado de épocas, nesse caso pode levar a um overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
